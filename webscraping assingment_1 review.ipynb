{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8471f6",
   "metadata": {},
   "source": [
    "DATA FRAME: wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608ec3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70bc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0739445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Header Text\n",
      "0                                  Contents\n",
      "1                              Web scraping\n",
      "2                             History[edit]\n",
      "3                          Techniques[edit]\n",
      "4                Human copy-and-paste[edit]\n",
      "5               Text pattern matching[edit]\n",
      "6                    HTTP programming[edit]\n",
      "7                        HTML parsing[edit]\n",
      "8                         DOM parsing[edit]\n",
      "9                Vertical aggregation[edit]\n",
      "10    Semantic annotation recognizing[edit]\n",
      "11  Computer vision web-page analysis[edit]\n",
      "12                           Software[edit]\n",
      "13                       Legal issues[edit]\n",
      "14                      United States[edit]\n",
      "15                     European Union[edit]\n",
      "16                          Australia[edit]\n",
      "17                              India[edit]\n",
      "18    Methods to prevent web scraping[edit]\n",
      "19                           See also[edit]\n",
      "20                         References[edit]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the content of the wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/Web_scraping\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Find all header tags and store their text in a list\n",
    "headers = []\n",
    "for header_tag in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "    headers.append(header_tag.text)\n",
    "\n",
    "# Create a data frame from the list of headers\n",
    "df = pd.DataFrame(headers, columns=[\"Header Text\"])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd674c8e",
   "metadata": {},
   "source": [
    "IMBD's top rated 50 movies: DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1a921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Name  Year Rating\n",
      "0    The Shawshank Redemption  1994    9.2\n",
      "1               The Godfather  1972    9.2\n",
      "2             The Dark Knight  2008    9.0\n",
      "3       The Godfather Part II  1974    9.0\n",
      "4                12 Angry Men  1957    9.0\n",
      "..                        ...   ...    ...\n",
      "245                  The Help  2011    8.0\n",
      "246                   Aladdin  1992    8.0\n",
      "247               Dersu Uzala  1975    8.0\n",
      "248                    Gandhi  1982    8.0\n",
      "249        Dances with Wolves  1990    8.0\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the content of the IMDb page\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Find all movie entries and store their name, rating, and year of release in a list\n",
    "movies = []\n",
    "for movie_entry in soup.find_all(\"td\", class_=\"titleColumn\"):\n",
    "    movie_name = movie_entry.find(\"a\").text\n",
    "    movie_year = movie_entry.find(\"span\").text[1:-1]\n",
    "    movie_rating = movie_entry.find_next(\"td\", class_=\"ratingColumn\").find(\"strong\").text\n",
    "    movies.append({\"Name\": movie_name, \"Year\": movie_year, \"Rating\": movie_rating})\n",
    "\n",
    "# Create a data frame from the list of movies\n",
    "df = pd.DataFrame(movies)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ec80a",
   "metadata": {},
   "source": [
    "IMBD's top rated 50 indian movies: DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a85844d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    name rating  year\n",
      "0    Ramayana: The Legend of Prince Rama    8.5  1993\n",
      "1             Rocketry: The Nambi Effect    8.4  2022\n",
      "2                               Gol Maal    8.4  1979\n",
      "3                                Nayakan    8.4  1987\n",
      "4                             Anbe Sivam    8.4  2003\n",
      "..                                   ...    ...   ...\n",
      "245                       Poove Unakkaga    7.7  1996\n",
      "246                        Minnal Murali    7.7  2021\n",
      "247                    Thiruchitrambalam    7.7  2022\n",
      "248                           Goodachari    7.7  2018\n",
      "249                                 Joji    7.6  2021\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.imdb.com/india/top-rated-indian-movies/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "movies = []\n",
    "rows = soup.find(\"tbody\", class_=\"lister-list\").find_all(\"tr\")\n",
    "for row in rows:\n",
    "    movie = {}\n",
    "    movie[\"name\"] = row.find(\"td\", class_=\"titleColumn\").a.text\n",
    "    movie[\"rating\"] = row.find(\"td\", class_=\"ratingColumn imdbRating\").strong.text\n",
    "    movie[\"year\"] = row.find(\"span\", class_=\"secondaryInfo\").text[1:5]\n",
    "    movies.append(movie)\n",
    "\n",
    "df = pd.DataFrame(movies)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd8355a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Rajendra Prasad\n",
      "Term of office: 26 January 1950 to 13 May 1962\n",
      "\n",
      "Name: Dr. Sarvepalli Radhakrishnan\n",
      "Term of office: 13 May 1962 to 13 May 1967\n",
      "\n",
      "Name: Dr. Zakir Hussain\n",
      "Term of office: 13 May 1967 to 3 May 1969\n",
      "\n",
      "Name: Varahagiri Venkata Giri\n",
      "Term of office: 24 August 1969 to 24 August 1974\n",
      "\n",
      "Name: Fakhruddin Ali Ahmed\n",
      "Term of office: 24 August 1974 to 11 February 1977\n",
      "\n",
      "Name: Neelam Sanjiva Reddy\n",
      "Term of office: 25 July 1977 to 25 July 1982\n",
      "\n",
      "Name: Giani Zail Singh\n",
      "Term of office: 25 July 1982 to 25 July 1987\n",
      "\n",
      "Name: Ramaswamy Venkataraman\n",
      "Term of office: 25 July 1987 to 25 July 1992\n",
      "\n",
      "Name: Shankar Dayal Sharma\n",
      "Term of office: 25 July 1992 to 25 July 1997\n",
      "\n",
      "Name: Kocheril Raman Narayanan\n",
      "Term of office: 25 July 1997 to 25 July 2002\n",
      "\n",
      "Name: A.P.J. Abdul Kalam\n",
      "Term of office: 25 July 2002 to 25 July 2007\n",
      "\n",
      "Name: Pratibha Patil\n",
      "Term of office: 25 July 2007 to 25 July 2012\n",
      "\n",
      "Name: Pranab Mukherjee\n",
      "Term of office: 25 July 2012 to 25 July 2017\n",
      "\n",
      "Name: Ram Nath Kovind\n",
      "Term of office: 25 July 2017 to 25 July 2022\n",
      "\n",
      "Name: Droupadi Murmu\n",
      "Term of office: 25 July 2022 to present\n",
      "\n"
     ]
    }
   ],
   "source": [
    "presidents = [    {\"Name\": \"Dr. Rajendra Prasad\", \"Term of office\": \"26 January 1950 to 13 May 1962\"},    {\"Name\": \"Dr. Sarvepalli Radhakrishnan\", \"Term of office\": \"13 May 1962 to 13 May 1967\"},    {\"Name\": \"Dr. Zakir Hussain\", \"Term of office\": \"13 May 1967 to 3 May 1969\"},    {\"Name\": \"Varahagiri Venkata Giri\", \"Term of office\": \"24 August 1969 to 24 August 1974\"},    {\"Name\": \"Fakhruddin Ali Ahmed\", \"Term of office\": \"24 August 1974 to 11 February 1977\"},    {\"Name\": \"Neelam Sanjiva Reddy\", \"Term of office\": \"25 July 1977 to 25 July 1982\"},    {\"Name\": \"Giani Zail Singh\", \"Term of office\": \"25 July 1982 to 25 July 1987\"},    {\"Name\": \"Ramaswamy Venkataraman\", \"Term of office\": \"25 July 1987 to 25 July 1992\"},    {\"Name\": \"Shankar Dayal Sharma\", \"Term of office\": \"25 July 1992 to 25 July 1997\"},    {\"Name\": \"Kocheril Raman Narayanan\", \"Term of office\": \"25 July 1997 to 25 July 2002\"},    {\"Name\": \"A.P.J. Abdul Kalam\", \"Term of office\": \"25 July 2002 to 25 July 2007\"},    {\"Name\": \"Pratibha Patil\", \"Term of office\": \"25 July 2007 to 25 July 2012\"},    {\"Name\": \"Pranab Mukherjee\", \"Term of office\": \"25 July 2012 to 25 July 2017\"},    {\"Name\": \"Ram Nath Kovind\", \"Term of office\": \"25 July 2017 to 25 July 2022\"}, {\"Name\": \"Droupadi Murmu\", \"Term of office\": \"25 July 2022 to present\"}]\n",
    "\n",
    "for president in presidents:\n",
    "    print(\"Name:\", president[\"Name\"])\n",
    "    print(\"Term of office:\", president[\"Term of office\"])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1dd362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name                      Term of office\n",
      "0            Dr. Rajendra Prasad      26 January 1950 to 13 May 1962\n",
      "1   Dr. Sarvepalli Radhakrishnan          13 May 1962 to 13 May 1967\n",
      "2              Dr. Zakir Hussain           13 May 1967 to 3 May 1969\n",
      "3        Varahagiri Venkata Giri    24 August 1969 to 24 August 1974\n",
      "4           Fakhruddin Ali Ahmed  24 August 1974 to 11 February 1977\n",
      "5           Neelam Sanjiva Reddy        25 July 1977 to 25 July 1982\n",
      "6               Giani Zail Singh        25 July 1982 to 25 July 1987\n",
      "7         Ramaswamy Venkataraman        25 July 1987 to 25 July 1992\n",
      "8           Shankar Dayal Sharma        25 July 1992 to 25 July 1997\n",
      "9       Kocheril Raman Narayanan        25 July 1997 to 25 July 2002\n",
      "10            A.P.J. Abdul Kalam        25 July 2002 to 25 July 2007\n",
      "11                Pratibha Patil        25 July 2007 to 25 July 2012\n",
      "12              Pranab Mukherjee        25 July 2012 to 25 July 2017\n",
      "13               Ram Nath Kovind        25 July 2017 to 25 July 2022\n",
      "14                Droupadi Murmu             25 July 2022 to present\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "presidents = [    {\"Name\": \"Dr. Rajendra Prasad\", \"Term of office\": \"26 January 1950 to 13 May 1962\"},    {\"Name\": \"Dr. Sarvepalli Radhakrishnan\", \"Term of office\": \"13 May 1962 to 13 May 1967\"},    {\"Name\": \"Dr. Zakir Hussain\", \"Term of office\": \"13 May 1967 to 3 May 1969\"},    {\"Name\": \"Varahagiri Venkata Giri\", \"Term of office\": \"24 August 1969 to 24 August 1974\"},    {\"Name\": \"Fakhruddin Ali Ahmed\", \"Term of office\": \"24 August 1974 to 11 February 1977\"},    {\"Name\": \"Neelam Sanjiva Reddy\", \"Term of office\": \"25 July 1977 to 25 July 1982\"},    {\"Name\": \"Giani Zail Singh\", \"Term of office\": \"25 July 1982 to 25 July 1987\"},    {\"Name\": \"Ramaswamy Venkataraman\", \"Term of office\": \"25 July 1987 to 25 July 1992\"},    {\"Name\": \"Shankar Dayal Sharma\", \"Term of office\": \"25 July 1992 to 25 July 1997\"},    {\"Name\": \"Kocheril Raman Narayanan\", \"Term of office\": \"25 July 1997 to 25 July 2002\"},    {\"Name\": \"A.P.J. Abdul Kalam\", \"Term of office\": \"25 July 2002 to 25 July 2007\"},    {\"Name\": \"Pratibha Patil\", \"Term of office\": \"25 July 2007 to 25 July 2012\"},    {\"Name\": \"Pranab Mukherjee\", \"Term of office\": \"25 July 2012 to 25 July 2017\"},    {\"Name\": \"Ram Nath Kovind\", \"Term of office\": \"25 July 2017 to 25 July 2022\"}, {\"Name\": \"Droupadi Murmu\", \"Term of office\": \"25 July 2022 to present\"}]\n",
    "\n",
    "df = pd.DataFrame(presidents)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fc9c08",
   "metadata": {},
   "source": [
    "ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e4a7be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Australia\\nAUS', 29), (2, 'India\\nIND', 32), (3, 'England\\nENG', 47), (4, 'South Africa\\nSA', 29), (5, 'New Zealand\\nNZ', 30), (6, 'Pakistan\\nPAK', 30), (7, 'Sri Lanka\\nSL', 26), (8, 'West Indies\\nWI', 28), (9, 'Bangladesh\\nBAN', 25), (10, 'Zimbabwe\\nZIM', 6)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.icc-cricket.com/rankings/mens/team-rankings/test\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "rankings = []\n",
    "for row in results.find_all(\"tr\"):\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) > 0:\n",
    "        rank = int(cols[0].text.strip())\n",
    "        team = cols[1].text.strip()\n",
    "        ratings = int(cols[2].text.strip())\n",
    "        rankings.append((rank, team, ratings))\n",
    "\n",
    "print(rankings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f407515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'India\\nIND', 44, 114), (2, 'Australia\\nAUS', 32, 112), (3, 'New Zealand\\nNZ', 29, 111), (4, 'England\\nENG', 33, 111), (5, 'Pakistan\\nPAK', 25, 106), (6, 'South Africa\\nSA', 27, 103), (7, 'Bangladesh\\nBAN', 33, 95), (8, 'Sri Lanka\\nSL', 34, 88), (9, 'Afghanistan\\nAFG', 20, 71), (10, 'West Indies\\nWI', 41, 71), (11, 'Ireland\\nIRE', 25, 52), (12, 'Scotland\\nSCO', 31, 47), (13, 'Zimbabwe\\nZIM', 28, 43), (14, 'Namibia\\nNAM', 26, 37), (15, 'Netherlands\\nNED', 21, 32), (16, 'Oman\\nOMA', 30, 31), (17, 'UAE\\nUAE', 25, 28), (18, 'United States\\nUSA', 31, 26), (19, 'Nepal\\nNEP', 28, 16), (20, 'Papua New Guinea\\nPNG', 30, 4)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "rankings = []\n",
    "for row in results.find_all(\"tr\"):\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) > 0:\n",
    "        rank = int(cols[0].text.strip())\n",
    "        team = cols[1].text.strip()\n",
    "        matches = int(cols[2].text.strip())\n",
    "        ratings = int(cols[4].text.strip())\n",
    "        rankings.append((rank, team, matches, ratings))\n",
    "\n",
    "print(rankings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c38f9534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "rankings = []\n",
    "for row in results.find_all(\"tr\"):\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) < 0:\n",
    "        rank = int(cols[0].text.strip())\n",
    "        points = int(cols[3].text.strip())\n",
    "        rankings.append((rank, points))\n",
    "\n",
    "print(rankings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb64ba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Batsmen in the ICC Rankings:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/batsmen\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "batsmen = soup.select(\"table tbody tr\")\n",
    "\n",
    "print(\"Top 10 Batsmen in the ICC Rankings:\")\n",
    "for i, batsman in enumerate(batsmen[0:10]):\n",
    "    name = batsman.select_one(\"td:nth-of-type(2) a\").getText().strip()\n",
    "    team = batsman.select_one(\"td:nth-of-type(4)\").getText().strip()\n",
    "    rating = batsman.select_one(\"td:nth-of-type(5)\").getText().strip()\n",
    "    \n",
    "    print(f\"{i+1}. {name} ({team}) - Rating: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab0eca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \n",
      "Rassie van der Dussen\n",
      " (\n",
      "\n",
      "SA\n",
      ") - 787\n",
      "2. \n",
      "David Warner\n",
      " (\n",
      "\n",
      "AUS\n",
      ") - 747\n",
      "3. \n",
      "Quinton de Kock\n",
      " (\n",
      "\n",
      "SA\n",
      ") - 743\n",
      "4. \n",
      "Imam-ul-Haq\n",
      " (\n",
      "\n",
      "PAK\n",
      ") - 740\n",
      "5. \n",
      "Shubman Gill\n",
      " (\n",
      "\n",
      "IND\n",
      ") - 734\n",
      "6. \n",
      "Virat Kohli\n",
      " (\n",
      "\n",
      "IND\n",
      ") - 727\n",
      "7. \n",
      "Steve Smith\n",
      " (\n",
      "\n",
      "AUS\n",
      ") - 719\n",
      "8. \n",
      "Rohit Sharma\n",
      " (\n",
      "\n",
      "IND\n",
      ") - 719\n",
      "9. \n",
      "Kane Williamson\n",
      " (\n",
      "\n",
      "NZ\n",
      ") - 700\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m rows \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mtbody\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     player_data \u001b[38;5;241m=\u001b[39m \u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     player_name \u001b[38;5;241m=\u001b[39m player_data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     15\u001b[0m     team \u001b[38;5;241m=\u001b[39m player_data[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "rows = table.tbody.find_all(\"tr\")\n",
    "\n",
    "for i in range(10):\n",
    "    player_data = rows[i].find_all(\"td\")\n",
    "    player_name = player_data[1].text\n",
    "    team = player_data[2].text\n",
    "    rating = player_data[3].text\n",
    "    \n",
    "    print(f\"{i+1}. {player_name} ({team}) - {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b67092d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Find the table with the rankings information\u001b[39;00m\n\u001b[1;32m      9\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtbody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Iterate through each row and extract the data\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rows[:\u001b[38;5;241m10\u001b[39m]):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Extract the rank, player name, team, and rating\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Find the table with the rankings information\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "\n",
    "rows = table.tbody.find_all(\"tr\")\n",
    "\n",
    "# Iterate through each row and extract the data\n",
    "for i, row in enumerate(rows[:10]):\n",
    "    # Extract the rank, player name, team, and rating\n",
    "    rank = row.find(\"td\", class_=\"table-body__cell\").text.strip()\n",
    "    player = row.find(\"span\", class_=\"table-body__cell\").text.strip()\n",
    "    team = row.find(\"td\", class_=\"table-body__cell team\").text.strip()\n",
    "    rating = row.find(\"td\", class_=\"table-body__cell u-text-right\").text.strip()\n",
    "\n",
    "    \n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Player: {player}\")\n",
    "    print(f\"Team: {team}\")\n",
    "    print(f\"Rating: {rating}\")\n",
    "    print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dfedf1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Australia\\nAUS', 21, 172), (2, 'England\\nENG', 28, 119), (3, 'South Africa\\nSA', 26, 119), (4, 'India\\nIND', 27, 104), (5, 'New Zealand\\nNZ', 25, 102), (6, 'West Indies\\nWI', 27, 94), (7, 'Bangladesh\\nBAN', 13, 76), (8, 'Thailand\\nTHA', 8, 72), (9, 'Pakistan\\nPAK', 27, 62), (10, 'Sri Lanka\\nSL', 8, 44), (11, 'Ireland\\nIRE', 14, 39), (12, 'Netherlands\\nNED', 9, 0), (13, 'Zimbabwe\\nZIM', 8, 0)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "rankings = []\n",
    "for row in results.find_all(\"tr\"):\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) > 0:\n",
    "        rank = int(cols[0].text.strip())\n",
    "        team = cols[1].text.strip()\n",
    "        matches = int(cols[2].text.strip())\n",
    "        ratings = int(cols[4].text.strip())\n",
    "        rankings.append((rank, team, matches, ratings))\n",
    "\n",
    "print(rankings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2953344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "rankings = []\n",
    "for row in results.find_all(\"tr\"):\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) < 0:\n",
    "        rank = int(cols[0].text.strip())\n",
    "        points = int(cols[3].text.strip())\n",
    "        rankings.append((rank, points))\n",
    "\n",
    "print(rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53362d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Player                 Team  \\\n",
      "0       2\\n                                \\n\\n\\n(0)          Beth Mooney   \n",
      "1       3\\n                                \\n\\n\\n(0)      Laura Wolvaardt   \n",
      "2       4\\n                                \\n\\n\\n(0)       Natalie Sciver   \n",
      "3  5\\n                                \\n\\n\\n\\n\\n(...          Meg Lanning   \n",
      "4  6\\n                                \\n\\n\\n\\n\\n(...     Harmanpreet Kaur   \n",
      "5  7\\n                                \\n\\n\\n\\n\\n(...      Smriti Mandhana   \n",
      "6       8\\n                                \\n\\n\\n(0)       Rachael Haynes   \n",
      "7       9\\n                                \\n\\n\\n(0)  Chamari Athapaththu   \n",
      "8      10\\n                                \\n\\n\\n(0)    Amy Satterthwaite   \n",
      "\n",
      "  Rating  \n",
      "0    AUS  \n",
      "1     SA  \n",
      "2    ENG  \n",
      "3    AUS  \n",
      "4    IND  \n",
      "5    IND  \n",
      "6    AUS  \n",
      "7     SL  \n",
      "8     NZ  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "players = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find(\"table\", attrs={\"class\": \"table\"})\n",
    "table_body = table.find(\"tbody\")\n",
    "\n",
    "rows = table_body.find_all(\"tr\")\n",
    "for row in rows[:10]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    player = cols[0].text.strip()\n",
    "    team = cols[1].text.strip()\n",
    "    rating = cols[2].text.strip()\n",
    "    players.append(player)\n",
    "    teams.append(team)\n",
    "    ratings.append(rating)\n",
    "\n",
    "data = {\"Player\": players, \"Team\": teams, \"Rating\": ratings}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a4c14",
   "metadata": {},
   "source": [
    "NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0993eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML content\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find all the news articles\n",
    "articles = soup.find_all('div', class_='ArticleCard-content')\n",
    "\n",
    "news_data = []\n",
    "\n",
    "for article in articles:\n",
    "    # Extract the headline\n",
    "    headline = article.find('h3', class_='headline').get_text().strip()\n",
    "    \n",
    "    # Extract the time\n",
    "    time = article.find('span', class_='time').get_text().strip()\n",
    "    \n",
    "    # Extract the link\n",
    "    link = article.find('a').get('href')\n",
    "    \n",
    "    data = {'Headline': headline, 'Time': time, 'Link': link}\n",
    "    \n",
    "    # Append the data to the list\n",
    "    news_data.append(data)\n",
    "\n",
    "# Create a Pandas dataframe from the news data\n",
    "df = pd.DataFrame(news_data)\n",
    "\n",
    "# Show the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4f8fc",
   "metadata": {},
   "source": [
    "ARTICLE FROM AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f1106de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "# Make a request to the website\n",
    "page = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML content\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find all the articles\n",
    "articles = soup.find_all('div', class_='item-details')\n",
    "\n",
    "article_data = []\n",
    "\n",
    "for article in articles:\n",
    "    # Extract the title\n",
    "    title = article.find('a', class_='title').get_text().strip()\n",
    "    \n",
    "    # Extract the authors\n",
    "    authors = article.find('div', class_='authors').get_text().strip()\n",
    "    \n",
    "    # Extract the published date\n",
    "    published_date = article.find('div', class_='date').get_text().strip()\n",
    "    \n",
    "    # Extract the paper URL\n",
    "    paper_url = article.find('a', class_='title').get('href')\n",
    "    \n",
    "    data = {'Title': title, 'Authors': authors, 'Published Date': published_date, 'Paper URL': paper_url}\n",
    "    \n",
    "    article_data.append(data)\n",
    "\n",
    "# Create a Pandas dataframe from the article data\n",
    "df = pd.DataFrame(article_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2a8d1",
   "metadata": {},
   "source": [
    "RESTAURANTS DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fdc2ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Restaurant Name, Cuisine, Location, Ratings, Image URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.dineout.co.in/restaurants'\n",
    "\n",
    "# Make a request to the website\n",
    "page = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML content\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find all the restaurants\n",
    "restaurants = soup.find_all('div', class_='col-lg-4 col-md-6 col-sm-12 mb-4')\n",
    "\n",
    "# Create a list to store the restaurant details\n",
    "restaurant_list = []\n",
    "\n",
    "# Loop through each restaurant\n",
    "for restaurant in restaurants:\n",
    "    # Extract the restaurant name\n",
    "    name = restaurant.find('h2', class_='h5 text-dark').get_text().strip()\n",
    "    \n",
    "    # Extract the cuisine\n",
    "    cuisine = restaurant.find('p', class_='text-secondary mb-0').get_text().strip()\n",
    "    \n",
    "    # Extract the location\n",
    "    location = restaurant.find('p', class_='text-secondary mb-0').get_text().strip()\n",
    "    \n",
    "    # Extract the ratings\n",
    "    ratings = restaurant.find('span', class_='text-secondary').get_text().strip()\n",
    "    \n",
    "    # Extract the image URL\n",
    "    image_url = restaurant.find('img').get('src')\n",
    "    \n",
    "    \n",
    "    restaurant_list.append([name, cuisine, location, ratings, image_url])\n",
    "\n",
    "df = pd.DataFrame(restaurant_list, columns=['Restaurant Name', 'Cuisine', 'Location', 'Ratings', 'Image URL'])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee5ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
