{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226b8318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./opt/anaconda3/lib/python3.9/site-packages (4.8.2)\n",
      "Requirement already satisfied: trio~=0.17 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b335ebe",
   "metadata": {},
   "source": [
    "MOST VIEWED YOUTUBE VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ffdb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name  \\\n",
      "0    1.                            \"Baby Shark Dance\"[4]   \n",
      "1    2.                                   \"Despacito\"[7]   \n",
      "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
      "3    4.                                  \"Bath Song\"[15]   \n",
      "4    5.                               \"Shape of You\"[16]   \n",
      "5    6.                              \"See You Again\"[18]   \n",
      "6    7.                \"Phonics Song with Two Words\"[23]   \n",
      "7    8.                          \"Wheels on the Bus\"[24]   \n",
      "8    9.                                \"Uptown Funk\"[25]   \n",
      "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
      "10  11.                              \"Gangnam Style\"[27]   \n",
      "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
      "12  13.                             \"Dame Tu Cosita\"[33]   \n",
      "13  14.                                      \"Sugar\"[34]   \n",
      "14  15.                                     \"Axel F\"[35]   \n",
      "15  16.                                       \"Roar\"[36]   \n",
      "16  17.                             \"Counting Stars\"[37]   \n",
      "17  18.                                      \"Sorry\"[38]   \n",
      "18  19.                          \"Thinking Out Loud\"[39]   \n",
      "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
      "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
      "21  22.                                 \"Dark Horse\"[42]   \n",
      "22  23.                                      \"Faded\"[43]   \n",
      "23  24.                                 \"Let Her Go\"[44]   \n",
      "24  25.                             \"Girls Like You\"[45]   \n",
      "25  26.                                    \"Perfect\"[46]   \n",
      "26  27.                                   \"Bailando\"[47]   \n",
      "27  28.                                    \"Lean On\"[48]   \n",
      "28  29.                             \"Lakdi Ki Kathi\"[49]   \n",
      "29  30.          \"Humpty the train on a fruits ride\"[50]   \n",
      "\n",
      "                                           Artist  Views        Upload Date  \n",
      "0     Pinkfong Baby Shark - Kids' Songs & Stories  12.37      June 17, 2016  \n",
      "1                                      Luis Fonsi   8.09   January 12, 2017  \n",
      "2                                     LooLoo Kids   6.63    October 8, 2016  \n",
      "3                      Cocomelon – Nursery Rhymes   6.03        May 2, 2018  \n",
      "4                                      Ed Sheeran   5.92   January 30, 2017  \n",
      "5                                     Wiz Khalifa   5.79      April 6, 2015  \n",
      "6                                       ChuChu TV   5.17      March 6, 2014  \n",
      "7                      Cocomelon – Nursery Rhymes   4.95       May 24, 2018  \n",
      "8                                     Mark Ronson   4.84  November 19, 2014  \n",
      "9                                     Miroshka TV   4.83  February 27, 2018  \n",
      "10                                            Psy   4.70      July 15, 2012  \n",
      "11                                     Get Movies   4.53   January 31, 2012  \n",
      "12                                      El Chombo   4.24      April 5, 2018  \n",
      "13                                       Maroon 5   3.82   January 14, 2015  \n",
      "14                                     Crazy Frog   3.76      June 16, 2009  \n",
      "15                                     Katy Perry   3.73  September 5, 2013  \n",
      "16                                    OneRepublic   3.73       May 31, 2013  \n",
      "17                                  Justin Bieber   3.63   October 22, 2015  \n",
      "18                                     Ed Sheeran   3.55    October 7, 2014  \n",
      "19                     Cocomelon – Nursery Rhymes   3.51      June 25, 2018  \n",
      "20                                        Shakira   3.48       June 4, 2010  \n",
      "21                                     Katy Perry   3.45  February 20, 2014  \n",
      "22                                    Alan Walker   3.41   December 3, 2015  \n",
      "23                                      Passenger   3.38      July 25, 2012  \n",
      "24                                       Maroon 5   3.37       May 31, 2018  \n",
      "25                                     Ed Sheeran   3.37   November 9, 2017  \n",
      "26                               Enrique Iglesias   3.34     April 11, 2014  \n",
      "27                                    Major Lazer   3.33     March 22, 2015  \n",
      "28                                   Jingle Toons   3.32      June 14, 2018  \n",
      "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   3.31   January 26, 2018  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"wikitable\")))\n",
    "    table = driver.find_element(By.CLASS_NAME, \"wikitable\")\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    \n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        try:\n",
    "            rank = row.find_elements(By.TAG_NAME, 'td')[0].text\n",
    "            name = row.find_elements(By.TAG_NAME, 'td')[1].text\n",
    "            artist = row.find_elements(By.TAG_NAME, 'td')[2].text\n",
    "            views = row.find_elements(By.TAG_NAME, 'td')[3].text\n",
    "            upload_date = row.find_elements(By.TAG_NAME, 'td')[4].text\n",
    "            data.append([rank, name, artist, views, upload_date])\n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "    df = pd.DataFrame(data, columns=[\"Rank\", \"Name\", \"Artist\", \"Views\", \"Upload Date\"])\n",
    "    print(df)\n",
    "    \n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55152348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e0e05",
   "metadata": {},
   "source": [
    "BCCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4641243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1b8146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sukanyasemwal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4f8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a4cd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the bcci.tv\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b55b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture_tag = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "fixture_tag.click()    \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a343f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      match                                     series  \\\n",
      "0  1st ODI   AUSTRALIA TOUR OF INDIA ODI SERIES 202223   \n",
      "\n",
      "                                              venue         date         time  \n",
      "0  Dr YS Rajasekhara Reddy ACAVDCA Cricket Stadium,  19 MAR 2023  1:30 PM IST  \n"
     ]
    }
   ],
   "source": [
    "# Wait for the elements to become visible\n",
    "time.sleep(10)\n",
    "\n",
    "# Scrape the required details\n",
    "matches = []\n",
    "series = []\n",
    "venues = []\n",
    "dates = []\n",
    "times = []\n",
    "\n",
    "try:\n",
    "    for title in driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[3]/div/div[1]/h5[2]/span'):\n",
    "        series.append(title.text.replace('-', \"\"))\n",
    "except NoSuchElementException:\n",
    "    series.append('-')\n",
    "\n",
    "try:\n",
    "    for match_title in driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[2]/div/div[4]/div/span[1]'):\n",
    "        matches.append(match_title.text.replace('-', \"\"))\n",
    "except NoSuchElementException:\n",
    "    matches.append('-')\n",
    "\n",
    "try:\n",
    "    for venue in driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[3]/div/div[4]/div/span[2]'):\n",
    "        venues.append(venue.text.replace('-', \"\"))\n",
    "except NoSuchElementException:\n",
    "    venues.append('-')\n",
    "\n",
    "try:\n",
    "    for fixture_date in driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[3]/div/div[1]/div/div[1]/h5'):\n",
    "        dates.append(fixture_date.text.replace('-', \"\"))\n",
    "except NoSuchElementException:\n",
    "    dates.append('-')\n",
    "\n",
    "try:\n",
    "    for fixture_time in driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[3]/div/div[1]/div/div[2]/h5'):\n",
    "        times.append(fixture_time.text.replace('-', \"\"))\n",
    "except NoSuchElementException:\n",
    "    times.append('-')\n",
    "\n",
    "# Ensure that all lists have the same number of elements\n",
    "num_items = len(matches)\n",
    "assert all(len(lst) == num_items for lst in [series, venues, dates, times])\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'match': matches,\n",
    "    'series': series,\n",
    "    'venue': venues,\n",
    "    'date': dates[0:8],\n",
    "    'time': times[0:8]\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc6b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14e760",
   "metadata": {},
   "source": [
    "STATE-WISE GDP OF INDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd853cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e760e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sukanyasemwal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41593c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the webdriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302d354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the website\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1617ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 'Economy' link and click it\n",
    "econ_link = driver.find_element(By.XPATH, \"//*[@id='top']/div[2]/div[2]/button\")\n",
    "econ_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f70129f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 'India' link and clik it\n",
    "india_link = driver.find_element(By.XPATH, \"//*[@id='top']/div[2]/div[2]/div/a[3]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0414d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 'GDP of Indian states' link and click it\n",
    "gdp_link = driver.find_element(By.XPATH, \"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "gdp_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09d1afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while scraping row: <selenium.webdriver.remote.webelement.WebElement (session=\"8148db7ed19e323cff7bbe98ce1f1c70\", element=\"31f642d1-013d-4042-b641-67f570a8570c\")>\n",
      "   Rank                      State GDP 2018-19 GDP 2019-20 Share 2018-19  \\\n",
      "0     1                Maharashtra           -   2,632,792        13.94%   \n",
      "1     2                 Tamil Nadu   1,845,853   1,630,208         8.63%   \n",
      "2     3              Uttar Pradesh   1,687,818   1,584,764         8.39%   \n",
      "3     4                    Gujarat           -   1,502,899         7.96%   \n",
      "4     5                  Karnataka   1,631,977   1,493,127         7.91%   \n",
      "5     6                West Bengal   1,253,832   1,089,898         5.77%   \n",
      "6     7                  Rajasthan   1,020,989     942,586         4.99%   \n",
      "7     8             Andhra Pradesh     972,782     862,957         4.57%   \n",
      "8     9                  Telangana     969,604     861,031         4.56%   \n",
      "9    10             Madhya Pradesh     906,672     809,592         4.29%   \n",
      "10   11                     Kerala           -     781,653         4.14%   \n",
      "11   12                      Delhi     856,112     774,870         4.10%   \n",
      "12   13                    Haryana     831,610     734,163         3.89%   \n",
      "13   14                      Bihar     611,804     530,363         2.81%   \n",
      "14   15                     Punjab     574,760     526,376         2.79%   \n",
      "15   16                     Odisha     521,275     487,805         2.58%   \n",
      "16   17                      Assam           -     315,881         1.67%   \n",
      "17   18               Chhattisgarh     329,180     304,063         1.61%   \n",
      "18   19                  Jharkhand     328,598     297,204         1.57%   \n",
      "19   20                Uttarakhand           -     245,895         1.30%   \n",
      "20   21            Jammu & Kashmir           -     155,956         0.83%   \n",
      "21   22           Himachal Pradesh     165,472     153,845         0.81%   \n",
      "22   23                        Goa      80,449      73,170         0.39%   \n",
      "23   24                    Tripura      55,984      49,845         0.26%   \n",
      "24   25                 Chandigarh           -      42,114         0.22%   \n",
      "25   26                 Puducherry      38,253      34,433         0.18%   \n",
      "26   27                  Meghalaya      36,572      33,481         0.18%   \n",
      "27   28                     Sikkim      32,496      28,723         0.15%   \n",
      "28   29                    Manipur      31,790      27,870         0.15%   \n",
      "29   30                   Nagaland           -      27,283         0.14%   \n",
      "30   31          Arunachal Pradesh           -      24,603         0.13%   \n",
      "31   32                    Mizoram      26,503      22,287         0.12%   \n",
      "32   33  Andaman & Nicobar Islands           -           -             -   \n",
      "33                           India  20,351,013  18,886,957                 \n",
      "\n",
      "   GDP Billion  \n",
      "0      399.921  \n",
      "1      247.629  \n",
      "2      240.726  \n",
      "3      228.290  \n",
      "4      226.806  \n",
      "5      165.556  \n",
      "6      143.179  \n",
      "7      131.083  \n",
      "8      130.791  \n",
      "9      122.977  \n",
      "10     118.733  \n",
      "11     117.703  \n",
      "12     111.519  \n",
      "13      80.562  \n",
      "14      79.957  \n",
      "15      74.098  \n",
      "16      47.982  \n",
      "17      46.187  \n",
      "18      45.145  \n",
      "19      37.351  \n",
      "20      23.690  \n",
      "21      23.369  \n",
      "22      11.115  \n",
      "23       7.571  \n",
      "24       6.397  \n",
      "25       5.230  \n",
      "26       5.086  \n",
      "27       4.363  \n",
      "28       4.233  \n",
      "29       4.144  \n",
      "30       3.737  \n",
      "31       3.385  \n",
      "32           -  \n",
      "33       2,869  \n"
     ]
    }
   ],
   "source": [
    "# scrape the table data\n",
    "table = driver.find_element(By.XPATH, \"//table[@id='table_id']\")\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# create empty lists to store the scraped data\n",
    "rank_list = []\n",
    "state_list = []\n",
    "gdp_18_19_list = []\n",
    "gdp_19_20_list = []\n",
    "share_18_19_list = []\n",
    "gdp_billion_list = []\n",
    "\n",
    "# iterate through the rows and extract the data\n",
    "for row in rows[1:]:\n",
    "    try:\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        rank_list.append(cols[0].text)\n",
    "        state_list.append(cols[1].text)\n",
    "        gdp_18_19_list.append(cols[2].text)\n",
    "        gdp_19_20_list.append(cols[3].text)\n",
    "        share_18_19_list.append(cols[4].text)\n",
    "        gdp_billion_list.append(cols[5].text)\n",
    "    except:\n",
    "        print(\"Error occurred while scraping row:\", row)\n",
    "\n",
    "# create a Pandas DataFrame using the scraped data\n",
    "df = pd.DataFrame({\n",
    "    'Rank': rank_list,\n",
    "    'State': state_list,\n",
    "    'GDP 2018-19': gdp_18_19_list,\n",
    "    'GDP 2019-20': gdp_19_20_list,\n",
    "    'Share 2018-19': share_18_19_list,\n",
    "    'GDP Billion': gdp_billion_list})\n",
    "\n",
    "# print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed368cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7acbaa",
   "metadata": {},
   "source": [
    "TRENDING REPOSITORY ON GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4720b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f91715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sukanyasemwal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9818cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the webdriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabc939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to website\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53dcf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log in to GitHub account\n",
    "username = \"your_username\"\n",
    "password = \"your_password\"\n",
    "\n",
    "sign_in_button_xpath = \"//a[contains(text(),'Sign in')]\"\n",
    "wait = WebDriverWait(driver, 10)\n",
    "sign_in_button = wait.until(EC.presence_of_element_located((By.XPATH, sign_in_button_xpath)))\n",
    "if sign_in_button.is_displayed():\n",
    "    sign_in_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db1f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the \"Explore\" dropdown menu\n",
    "explore_button = driver.find_element(By.XPATH, \"//*[@id='global-nav']/a[5]\")\n",
    "explore_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7859b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on \"Trending\" option\n",
    "trending_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[6]/main/div[1]/nav/div/a[3]\")\n",
    "trending_button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74e809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repos: ['https://github.com/microsoft/visual-chatgpt', 'https://github.com/ggerganov/whisper.cpp', 'https://github.com/oobabooga/text-generation-webui', 'https://github.com/sindresorhus/awesome', 'https://github.com/yetone/openai-translator', 'https://github.com/wong2/chatgpt-google-extension', 'https://github.com/caesarHQ/textSQL', 'https://github.com/EbookFoundation/free-programming-books', 'https://github.com/public-apis/public-apis', 'https://github.com/ggerganov/llama.cpp', 'https://github.com/davinci1012/pinduoduo_backdoor_unpacker', 'https://github.com/GanymedeNil/document.ai', 'https://github.com/camenduru/stable-diffusion-webui-colab', 'https://github.com/ann-afame/DEVOPS-WORLD', 'https://github.com/web-infra-dev/rspack', 'https://github.com/kamranahmedse/developer-roadmap', 'https://github.com/randaller/llama-chat', 'https://github.com/neovim/neovim', 'https://github.com/IHP-GmbH/IHP-Open-PDK', 'https://github.com/butaixianran/Stable-Diffusion-Webui-Civitai-Helper', 'https://github.com/guillaumekln/faster-whisper', 'https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111', 'https://github.com/geohot/tinygrad', 'https://github.com/getaurora/download', 'https://github.com/Azure-Samples/azure-search-openai-demo']\n",
      "Descriptions: ['Official repo for the paper: Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models', \"Port of OpenAI's Whisper model in C/C++\", 'A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.', '😎 Awesome lists about all kinds of interesting topics', '基于 ChatGPT API 的划词翻译浏览器插件和跨平台桌面端应用 - Browser extension and cross-platform desktop application for translation based on ChatGPT API.', 'A browser extension that enhance search engines with ChatGPT', '📚 Freely available programming books', 'A collective list of free APIs', \"Port of Facebook's LLaMA model in C/C++\", 'Samples and Unpacker of malicious backdoors and exploits developed and used by Pinduoduo', '基于向量数据库与GPT3.5的通用本地知识库方案(A universal local knowledge base solution based on vector database and GPT3.5)', 'stable diffusion webui colab', 'A fast Rust-based web bundler 🦀️', 'Interactive roadmaps, guides and other educational content to help developers grow in their careers.', \"Chat with Meta's LLaMA models at home made easy\", 'Vim-fork focused on extensibility and usability', '130nm BiCMOS Open Source PDK, dedicated for Analog, Mixed Signal and RF Design', 'Stable Diffusion Webui Extension for Civitai, to manage your model much more easily.', 'Faster Whisper transcription with CTranslate2', 'MultiDiffusion implementation with VAE VRAM optimize', 'You like pytorch? You like micrograd? You love tinygrad! ❤️', '极光官方版本下载页 翻墙 代理 科学上网 外网 加速器 梯子 路由', 'Demonstration of how to leverage Azure OpenAI and Cognitive Search to enable Information Search and Discovery over organizational content']\n",
      "Contributors Count: []\n",
      "Languages Used: ['Python', 'C', 'Python', 'TypeScript', 'TypeScript', 'JavaScript', 'Python', 'C', 'Java', 'Python', 'Jupyter Notebook', 'Rust', 'Astro', 'Python', 'Vim Script', 'HTML', 'Python', 'Python', 'Python', 'Python', 'Python']\n",
      "                                     Repository Title  \\\n",
      "0                          microsoft / visual-chatgpt   \n",
      "1                             ggerganov / whisper.cpp   \n",
      "2                   oobabooga / text-generation-webui   \n",
      "3                              sindresorhus / awesome   \n",
      "4                          yetone / openai-translator   \n",
      "5                    wong2 / chatgpt-google-extension   \n",
      "6                                  caesarHQ / textSQL   \n",
      "7            EbookFoundation / free-programming-books   \n",
      "8                           public-apis / public-apis   \n",
      "9                               ggerganov / llama.cpp   \n",
      "10          davinci1012 / pinduoduo_backdoor_unpacker   \n",
      "11                          GanymedeNil / document.ai   \n",
      "12           camenduru / stable-diffusion-webui-colab   \n",
      "13                           ann-afame / DEVOPS-WORLD   \n",
      "14                             web-infra-dev / rspack   \n",
      "15                  kamranahmedse / developer-roadmap   \n",
      "16                             randaller / llama-chat   \n",
      "17                                    neovim / neovim   \n",
      "18                            IHP-GmbH / IHP-Open-PDK   \n",
      "19  butaixianran / Stable-Diffusion-Webui-Civitai-...   \n",
      "20                      guillaumekln / faster-whisper   \n",
      "21  pkuliyi2015 / multidiffusion-upscaler-for-auto...   \n",
      "22                                  geohot / tinygrad   \n",
      "23                               getaurora / download   \n",
      "24           Azure-Samples / azure-search-openai-demo   \n",
      "\n",
      "                               Repository Description Contributors Count  \\\n",
      "0   Official repo for the paper: Visual ChatGPT: T...                  -   \n",
      "1             Port of OpenAI's Whisper model in C/C++                  -   \n",
      "2   A gradio web UI for running Large Language Mod...                  -   \n",
      "3   😎 Awesome lists about all kinds of interesting...                  -   \n",
      "4   基于 ChatGPT API 的划词翻译浏览器插件和跨平台桌面端应用 - Browser e...                  -   \n",
      "5   A browser extension that enhance search engine...                  -   \n",
      "6                📚 Freely available programming books                  -   \n",
      "7                      A collective list of free APIs                  -   \n",
      "8             Port of Facebook's LLaMA model in C/C++                  -   \n",
      "9   Samples and Unpacker of malicious backdoors an...                  -   \n",
      "10  基于向量数据库与GPT3.5的通用本地知识库方案(A universal local kno...                  -   \n",
      "11                       stable diffusion webui colab                  -   \n",
      "12                   A fast Rust-based web bundler 🦀️                  -   \n",
      "13  Interactive roadmaps, guides and other educati...                  -   \n",
      "14    Chat with Meta's LLaMA models at home made easy                  -   \n",
      "15    Vim-fork focused on extensibility and usability                  -   \n",
      "16  130nm BiCMOS Open Source PDK, dedicated for An...                  -   \n",
      "17  Stable Diffusion Webui Extension for Civitai, ...                  -   \n",
      "18      Faster Whisper transcription with CTranslate2                  -   \n",
      "19  MultiDiffusion implementation with VAE VRAM op...                  -   \n",
      "20  You like pytorch? You like micrograd? You love...                  -   \n",
      "21                  极光官方版本下载页 翻墙 代理 科学上网 外网 加速器 梯子 路由                  -   \n",
      "22  Demonstration of how to leverage Azure OpenAI ...                  -   \n",
      "23                                                  -                  -   \n",
      "24                                                  -                  -   \n",
      "\n",
      "       Language Used  \n",
      "0             Python  \n",
      "1                  C  \n",
      "2             Python  \n",
      "3         TypeScript  \n",
      "4         TypeScript  \n",
      "5         JavaScript  \n",
      "6             Python  \n",
      "7                  C  \n",
      "8               Java  \n",
      "9             Python  \n",
      "10  Jupyter Notebook  \n",
      "11              Rust  \n",
      "12             Astro  \n",
      "13            Python  \n",
      "14        Vim Script  \n",
      "15              HTML  \n",
      "16            Python  \n",
      "17            Python  \n",
      "18            Python  \n",
      "19            Python  \n",
      "20            Python  \n",
      "21                 -  \n",
      "22                 -  \n",
      "23                 -  \n",
      "24                 -  \n"
     ]
    }
   ],
   "source": [
    "# wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# get the repo titles and descriptions\n",
    "repo_titles = []\n",
    "repo_descs = []\n",
    "contributors = []\n",
    "languages = []\n",
    "\n",
    "# scrape the data from the trending repositories\n",
    "repos = driver.find_elements(By.XPATH, \"//h1[@class='h3 lh-condensed']/a\")\n",
    "print(\"Repos:\", [repo.get_attribute('href') for repo in repos])\n",
    "\n",
    "descs = driver.find_elements(By.XPATH, \"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "print(\"Descriptions:\", [desc.text.strip() for desc in descs] if descs else [])\n",
    "\n",
    "contributors_count = driver.find_elements(By.XPATH, \"//*[contains(text(),'Contributors')]\")\n",
    "print(\"Contributors Count:\", [count.text.strip() for count in contributors_count] if contributors_count else [])\n",
    "\n",
    "languages_used = driver.find_elements(By.XPATH, \"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "print(\"Languages Used:\", [language.text.strip() for language in languages_used] if languages_used else [])\n",
    "\n",
    "# extract the data from the elements and append to the lists\n",
    "for i in range(len(repos)):\n",
    "    title = repos[i].text.strip()\n",
    "    if title:\n",
    "        repo_titles.append(title)\n",
    "    else:\n",
    "        repo_titles.append('-')\n",
    "    if descs and i < len(descs):\n",
    "        description = descs[i].text.strip()\n",
    "    else:\n",
    "        description = '-'\n",
    "    if description:\n",
    "        repo_descs.append(description)\n",
    "    else:\n",
    "        repo_descs.append('-')\n",
    "    contributor_count = contributors_count[i+1].text.strip() if contributors_count and i+1 < len(contributors_count) else '-'\n",
    "    if contributor_count:\n",
    "        contributors.append(contributor_count)\n",
    "    else:\n",
    "        contributors.append('-')\n",
    "    language = languages_used[i].text.strip() if i < len(languages_used) else '-'\n",
    "    if language:\n",
    "        languages.append(language)\n",
    "    else:\n",
    "        languages.append('-')\n",
    "        \n",
    "# create a dataframe from the scraped data\n",
    "df = pd.DataFrame({\n",
    "    \"Repository Title\": repo_titles,\n",
    "    \"Repository Description\": repo_descs,\n",
    "    \"Contributors Count\": contributors,\n",
    "    \"Language Used\": languages})\n",
    "\n",
    "# print the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd647197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2775b",
   "metadata": {},
   "source": [
    "BILLIBOARD TOP 100 SONGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e3c4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbff60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching the chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85580c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the bcci.tv\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3a82c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the \"Charts\" option and then the \"Hot 100\" link\n",
    "charts_option = driver.find_element(By.XPATH, \"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "charts_option.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0302f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_100_link = driver.find_element(By.XPATH, \"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a\")\n",
    "hot_100_link.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd73f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs: ['', '', '', '', '', 'Die For You', '', '', '', 'Flowers', '', '', '', 'Kill Bill', '', '', '', \"Boy's A Liar, Pt. 2\", '', '', '', 'Last Night', '', '', '', \"Creepin'\", '', '', '', 'TQG', '', '', '', 'Unholy', '', '', '', 'Anti-Hero', '', '', '', 'Cuff It', '', '', '', \"I'm Good (Blue)\", '', '', '', 'Just Wanna Rock', '', '', '', 'Thought You Should Know', '', '', '', 'As It Was', '', '', '', 'Calm Down', '', '', '', 'Players', '', '', '', 'Rock And A Hard Place', '', '', '', 'Under The Influence', '', '', '', 'Thank God', '', '', '', 'Rich Flex', '', '', '', 'You Proof', '', '', '', 'Escapism', '', '', '', 'Lavender Haze', '', '', '', 'Going, Going, Gone', '', '', '', 'Painting Pictures', '', '', '', 'Something In The Orange', '', '', '', 'Until I Found You', '', '', '', 'Sure Thing', '', '', '', 'Heart Like A Truck', '', '', '', 'Superhero (Heroes & Villains)', '', '', '', 'Golden Hour', '', '', '', 'Snooze', '', '', '', 'Shirt', '', '', '', 'Made You Look', '', '', '', 'Bad Habit', '', '', '', 'The Kind Of Love We Make', '', '', '', 'I Like You (A Happier Song)', '', '', '', 'Wait For U', '', '', '', 'Love You Anyway', '', '', '', 'Wait In The Truck', '', '', '', 'Bebe Dame', '', '', '', 'Bzrp Music Sessions, Vol. 53', '', '', '', 'Nobody Gets Me', '', '', '', 'Favorite Song', '', '', '', 'She Had Me At Heads Carolina', '', '', '', 'Bloody Mary', '', '', '', 'Spin Bout U', '', '', '', 'X Si Volvemos', '', '', '', 'Unstoppable', '', '', '', 'About Damn Time', '', '', '', 'One Thing At A Time', '', '', '', 'Dawns', '', '', '', 'Special', '', '', '', \"What He Didn't Do\", '', '', '', 'Handle On You', '', '', '', 'Watch This (ARIZONATEARS Pluggnb Remix)', '', '', '', 'Que Vuelvas', '', '', '', 'Wild As Her', '', '', '', 'Love Again', '', '', '', 'Ceilings', '', '', '', 'Freestyle', '', '', '', 'Heaven', '', '', '', 'Low', '', '', '', 'I Wrote The Book', '', '', '', 'Lift Me Up', '', '', '', 'Kant Nobody', '', '', '', 'Next Thing You Know', '', '', '', 'Mientras Me Curo del Cora', '', '', '', 'In Ha Mood', '', '', '', 'Tennessee Orange', '', '', '', 'Gucci Los Panos', '', '', '', 'Private Landing', '', '', '', 'Tus Gafitas', '', '', '', 'Gatubela', '', '', '', 'Nonsense', '', '', '', 'Forever', '', '', '', 'No More Talk', '', '', '', \"You Didn't\", '', '', '', 'Split', '', '', '', 'AMG', '', '', '', '10:35', '', '', '', 'Cairo', '', '', '', 'Shmunk', '', '', '', 'Hope', '', '', '', \"That's What Tequila Does\", '', '', '', 'Pero Tu', '', '', '', 'Trance', '', '', '', 'Dirt', '', '', '', 'Joe', '', '', '', 'Gold', '', '', '', 'PRC', '', '', '', 'Human', '', '', '', 'Everything I Love', '', '', '', 'Here With Me', '', '', '', 'Ojos Ferrari', '', '', '', 'Besties', '', '', '', 'Yandel 150', '', '', '', 'Manana Sera Bonito', '', '', '', 'The Color Violet', '', '', '', 'Die 4 Me', '', '', '', 'Oscars: Complete Winners List', 'Donald Trump Is Reportedly Planning on Leaking Bombshell Letters from This British Royal Family Member in His New Book', '$2 Billion Powerball Winner Buys Rakish Hollywood Hills Mansion', 'Top 50 Highest-Paid Athletes of All Time', 'Oscars: Why the Success of Netflix’s ‘All Quiet on the Western Front’ Will Add Momentum to Germany’s Film Funding Reform', 'Rihanna Honors Spirit Of Chadwick Boseman With 2023 Oscars Performance', 'EXCLUSIVE: Puma Teams Up With Palomo Spain for Surf-Inspired Capsule Collection', '', '', 'Follow Us', '', 'The Daily', 'Have a Tip?']\n",
      "Artists Info: ['The Weeknd & Ariana Grande', 'Miley Cyrus', 'SZA', 'PinkPantheress & Ice Spice', 'Morgan Wallen', 'Metro Boomin, The Weeknd & 21 Savage', 'Karol G x Shakira', 'Sam Smith & Kim Petras', 'Taylor Swift', 'Beyonce', 'David Guetta & Bebe Rexha', 'Lil Uzi Vert', 'Morgan Wallen', 'Harry Styles', 'Rema & Selena Gomez', 'Coi Leray', 'Bailey Zimmerman', 'Chris Brown', 'Kane Brown With Katelyn Brown', 'Drake & 21 Savage', 'Morgan Wallen', 'RAYE Featuring 070 Shake', 'Taylor Swift', 'Luke Combs', 'Superstar Pride', 'Zach Bryan', 'Stephen Sanchez', 'Miguel', 'Lainey Wilson', 'Metro Boomin, Future & Chris Brown', 'JVKE', 'SZA', 'SZA', 'Meghan Trainor', 'Steve Lacy', 'Luke Combs', 'Post Malone Featuring Doja Cat', 'Future Featuring Drake & Tems', 'Luke Combs', 'HARDY Featuring Lainey Wilson', 'Fuerza Regida X Grupo Frontera', 'Bizarrap & Shakira', 'SZA', 'Toosii', 'Cole Swindell', 'Lady Gaga', 'Drake & 21 Savage', 'Karol G x Romeo Santos', 'Sia', 'Lizzo', 'Morgan Wallen', 'Zach Bryan Featuring Maggie Rogers', 'Lizzo Featuring SZA', 'Carly Pearce', 'Parker McCollum', 'Lil Uzi Vert', 'Carin Leon X Grupo Frontera', 'Corey Kent', 'The Kid LAROI', 'Lizzy McAlpine', 'Lil Baby', 'Niall Horan', 'SZA', 'Morgan Wallen', 'Rihanna', 'Lil Wayne Featuring DMX', 'Jordan Davis', 'Karol G', 'Ice Spice', 'Megan Moroney', 'Karol G', 'Don Toliver Featuring Justin Bieber & Future', 'Karol G', 'Karol G x Maldy', 'Sabrina Carpenter', 'Lil Baby Featuring Fridayy', 'Yeat', 'Brett Young', 'Yeat', 'Gabito Ballesteros, Peso Pluma & Natanael Cano', 'Tiesto Featuring Tate McRae', 'Karol G & Ovy On The Drums', 'Yeat Featuring YoungBoy Never Broke Again', 'NF', 'Jason Aldean', 'Karol G & Quevedo', 'Metro Boomin, Travis Scott & Young Thug', 'Key Glock', 'Luke Combs', 'Dierks Bentley', 'Peso Pluma X Natanael Cano', 'Cody Johnson', 'Morgan Wallen', 'd4vd', 'Karol G, Justin Quiles & Angel Dior', 'Karol G', 'Yandel & Feid', 'Karol G & Carla Morrison', 'Tory Lanez', 'Halsey']\n",
      "Last Week Ranks Info: ['6', '1', '2', '3', '5', '4', '-', '7', '8', '9', '10', '11', '15', '12', '19', '17', '16', '18', '13', '14', '20', '23', '22', '24', '34', '26', '31', '28', '29', '25', '27', '33', '32', '21', '30', '36', '37', '35', '38', '41', '39', '40', '48', '51', '42', '47', '57', '91', '50', '45', '60', '43', '55', '53', '58', '62', '56', '59', '54', '75', '64', '63', '65', '61', '52', '-', '67', '-', '68', '66', '-', '-', '-', '-', '72', '81', '-', '71', '-', '70', '73', '-', '-', '49', '77', '-', '76', '-', '-', '99', '79', '85', '80', '78', '-', '-', '90', '-', '84', '-']\n",
      "Peak Ranks Info: ['1', '1', '2', '3', '3', '3', '7', '1', '1', '6', '4', '10', '12', '1', '15', '16', '16', '12', '13', '2', '5', '22', '2', '23', '25', '10', '23', '28', '29', '8', '10', '29', '11', '11', '1', '8', '3', '1', '15', '23', '25', '9', '10', '44', '16', '46', '5', '48', '28', '1', '37', '42', '52', '53', '55', '56', '50', '58', '40', '60', '59', '62', '17', '38', '2', '66', '67', '68', '68', '53', '71', '72', '73', '37', '56', '8', '77', '63', '79', '66', '69', '82', '83', '49', '77', '86', '42', '88', '89', '90', '73', '84', '51', '60', '95', '96', '90', '98', '63', '100']\n",
      "Weeks on Board Info: ['31', '7', '12', '4', '5', '13', '1', '23', '19', '29', '27', '20', '29', '48', '26', '9', '38', '25', '25', '17', '42', '13', '19', '16', '3', '45', '35', '31', '16', '13', '27', '12', '18', '19', '35', '32', '36', '41', '3', '26', '10', '7', '12', '2', '36', '9', '17', '4', '29', '42', '13', '5', '3', '11', '9', '2', '10', '21', '5', '2', '22', '2', '12', '5', '18', '1', '6', '1', '4', '12', '1', '1', '1', '11', '7', '8', '1', '8', '1', '6', '6', '1', '1', '2', '8', '1', '4', '1', '1', '2', '4', '7', '5', '9', '1', '1', '4', '1', '9', '1']\n",
      "418\n",
      "418\n",
      "418\n",
      "418\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# wait for the page to load\n",
    "time.sleep(10)\n",
    "\n",
    "# get the song, artist, last week rank, peak rank, and weeks on board for each song in the hot 100\n",
    "songs = []\n",
    "artists_info = []\n",
    "last_week_ranks_info = []\n",
    "peak_ranks_info = []\n",
    "weeks_on_board_info = []\n",
    "\n",
    "# scrape the data from the Hot 100 songs chart\n",
    "songs = driver.find_elements(By.XPATH, \"//*[@id='title-of-a-story']\")\n",
    "print(\"Songs:\", [song.text.strip() for song in songs] if songs else [])\n",
    "\n",
    "artists_info = driver.find_elements(By.XPATH, \"//li[@class='lrv-u-width-100p']/ul/li[1]/span\")\n",
    "print(\"Artists Info:\", [artist.text.strip() for artist in artists_info] if artists_info else [])\n",
    "\n",
    "last_week_ranks_info = driver.find_elements(By.XPATH, \"//li[@class='lrv-u-width-100p']/ul/li[4]/span[1]\")\n",
    "print(\"Last Week Ranks Info:\", [rank.text.strip() for rank in last_week_ranks_info] if last_week_ranks_info else [])\n",
    "\n",
    "peak_ranks_info = driver.find_elements(By.XPATH, \"//li[@class='lrv-u-width-100p']/ul/li[5]/span[1]\")\n",
    "print(\"Peak Ranks Info:\", [rank.text.strip() for rank in peak_ranks_info] if peak_ranks_info else [])\n",
    "\n",
    "weeks_on_board_info = driver.find_elements(By.XPATH, \"//li[@class='lrv-u-width-100p']/ul/li[6]/span[1]\")\n",
    "print(\"Weeks on Board Info:\", [weeks.text.strip() for weeks in weeks_on_board_info] if weeks_on_board_info else [])\n",
    "\n",
    "songs_list = []\n",
    "artists_list = []\n",
    "last_week_ranks_list = []\n",
    "peak_ranks_list = []\n",
    "weeks_on_board_list = []\n",
    "\n",
    "for i in range(len(songs)):\n",
    "    song = songs[i].text.strip()\n",
    "    if song:\n",
    "        songs_list.append(song)\n",
    "    else:\n",
    "        songs_list.append('-')\n",
    "    artist = artists_info[i].text.strip() if i < len(artists_info) else '-'\n",
    "    if artist:\n",
    "        artists_list.append(artist)\n",
    "    else:\n",
    "        artists_list.append('-')\n",
    "    last_week_rank = last_week_ranks_info[i].text.strip() if i < len(last_week_ranks_info) else '-'\n",
    "    if last_week_rank:\n",
    "        last_week_ranks_list.append(last_week_rank)\n",
    "    else:\n",
    "        last_week_ranks_list.append('-')\n",
    "    peak_rank = peak_ranks_info[i].text.strip() if i < len(peak_ranks_info) else '-'\n",
    "    if peak_rank:\n",
    "        peak_ranks_list.append(peak_rank)\n",
    "    else:\n",
    "        peak_ranks_list.append('-')\n",
    "    weeks_on_board = weeks_on_board_info[i].text.strip() if i < len(weeks_on_board_info) else '-'\n",
    "    if weeks_on_board:\n",
    "        weeks_on_board_list.append(weeks_on_board)\n",
    "    else:\n",
    "        weeks_on_board_list.append('-')\n",
    "        \n",
    "print(len(songs_list))\n",
    "print(len(artists_list))\n",
    "print(len(last_week_ranks_list))\n",
    "print(len(peak_ranks_list))\n",
    "print(len(weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d5f63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9956b29",
   "metadata": {},
   "source": [
    "TOP SELLING BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57b2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76740d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching the chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the URL\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc772f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Name: Harry Potter and the Deathly Hallows\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 4,475,152\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Harry Potter and the Philosopher's Stone\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 4,200,654\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Harry Potter and the Order of the Phoenix\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 4,179,479\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Fifty Shades of Grey\n",
      "Author Name: James, E. L.\n",
      "Volumes Sold: 3,758,936\n",
      "Publisher: Random House\n",
      "Genre: Romance & Sagas\n",
      "\n",
      "Book Name: Harry Potter and the Goblet of Fire\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 3,583,215\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Harry Potter and the Chamber of Secrets\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 3,484,047\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Harry Potter and the Prisoner of Azkaban\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 3,377,906\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Angels and Demons\n",
      "Author Name: Brown, Dan\n",
      "Volumes Sold: 3,193,946\n",
      "Publisher: Transworld\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Harry Potter and the Half-blood Prince:Children's Edition\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 2,950,264\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Fifty Shades Darker\n",
      "Author Name: James, E. L.\n",
      "Volumes Sold: 2,479,784\n",
      "Publisher: Random House\n",
      "Genre: Romance & Sagas\n",
      "\n",
      "Book Name: Twilight\n",
      "Author Name: Meyer, Stephenie\n",
      "Volumes Sold: 2,315,405\n",
      "Publisher: Little, Brown Book\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: Girl with the Dragon Tattoo,The:Millennium Trilogy\n",
      "Author Name: Larsson, Stieg\n",
      "Volumes Sold: 2,233,570\n",
      "Publisher: Quercus\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Fifty Shades Freed\n",
      "Author Name: James, E. L.\n",
      "Volumes Sold: 2,193,928\n",
      "Publisher: Random House\n",
      "Genre: Romance & Sagas\n",
      "\n",
      "Book Name: Lost Symbol,The\n",
      "Author Name: Brown, Dan\n",
      "Volumes Sold: 2,183,031\n",
      "Publisher: Transworld\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: New Moon\n",
      "Author Name: Meyer, Stephenie\n",
      "Volumes Sold: 2,152,737\n",
      "Publisher: Little, Brown Book\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: Deception Point\n",
      "Author Name: Brown, Dan\n",
      "Volumes Sold: 2,062,145\n",
      "Publisher: Transworld\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Eclipse\n",
      "Author Name: Meyer, Stephenie\n",
      "Volumes Sold: 2,052,876\n",
      "Publisher: Little, Brown Book\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: Lovely Bones,The\n",
      "Author Name: Sebold, Alice\n",
      "Volumes Sold: 2,005,598\n",
      "Publisher: Pan Macmillan\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Curious Incident of the Dog in the Night-time,The\n",
      "Author Name: Haddon, Mark\n",
      "Volumes Sold: 1,979,552\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Digital Fortress\n",
      "Author Name: Brown, Dan\n",
      "Volumes Sold: 1,928,900\n",
      "Publisher: Transworld\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Short History of Nearly Everything,A\n",
      "Author Name: Bryson, Bill\n",
      "Volumes Sold: 1,852,919\n",
      "Publisher: Transworld\n",
      "Genre: Popular Science\n",
      "\n",
      "Book Name: Girl Who Played with Fire,The:Millennium Trilogy\n",
      "Author Name: Larsson, Stieg\n",
      "Volumes Sold: 1,814,784\n",
      "Publisher: Quercus\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Breaking Dawn\n",
      "Author Name: Meyer, Stephenie\n",
      "Volumes Sold: 1,787,118\n",
      "Publisher: Little, Brown Book\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: Very Hungry Caterpillar,The:The Very Hungry Caterpillar\n",
      "Author Name: Carle, Eric\n",
      "Volumes Sold: 1,783,535\n",
      "Publisher: Penguin\n",
      "Genre: Picture Books\n",
      "\n",
      "Book Name: Gruffalo,The\n",
      "Author Name: Donaldson, Julia\n",
      "Volumes Sold: 1,781,269\n",
      "Publisher: Pan Macmillan\n",
      "Genre: Picture Books\n",
      "\n",
      "Book Name: Jamie's 30-Minute Meals\n",
      "Author Name: Oliver, Jamie\n",
      "Volumes Sold: 1,743,266\n",
      "Publisher: Penguin\n",
      "Genre: Food & Drink: General\n",
      "\n",
      "Book Name: Kite Runner,The\n",
      "Author Name: Hosseini, Khaled\n",
      "Volumes Sold: 1,629,119\n",
      "Publisher: Bloomsbury\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: One Day\n",
      "Author Name: Nicholls, David\n",
      "Volumes Sold: 1,616,068\n",
      "Publisher: Hodder & Stoughton\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Thousand Splendid Suns,A\n",
      "Author Name: Hosseini, Khaled\n",
      "Volumes Sold: 1,583,992\n",
      "Publisher: Bloomsbury\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\n",
      "Author Name: Larsson, Stieg\n",
      "Volumes Sold: 1,555,135\n",
      "Publisher: Quercus\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Time Traveler's Wife,The\n",
      "Author Name: Niffenegger, Audrey\n",
      "Volumes Sold: 1,546,886\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Atonement\n",
      "Author Name: McEwan, Ian\n",
      "Volumes Sold: 1,539,428\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Bridget Jones's Diary:A Novel\n",
      "Author Name: Fielding, Helen\n",
      "Volumes Sold: 1,508,205\n",
      "Publisher: Pan Macmillan\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: World According to Clarkson,The\n",
      "Author Name: Clarkson, Jeremy\n",
      "Volumes Sold: 1,489,403\n",
      "Publisher: Penguin\n",
      "Genre: Humour: Collections & General\n",
      "\n",
      "Book Name: Captain Corelli's Mandolin\n",
      "Author Name: Bernieres, Louis de\n",
      "Volumes Sold: 1,352,318\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Sound of Laughter,The\n",
      "Author Name: Kay, Peter\n",
      "Volumes Sold: 1,310,207\n",
      "Publisher: Random House\n",
      "Genre: Autobiography: General\n",
      "\n",
      "Book Name: Life of Pi\n",
      "Author Name: Martel, Yann\n",
      "Volumes Sold: 1,310,176\n",
      "Publisher: Canongate\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Billy Connolly\n",
      "Author Name: Stephenson, Pamela\n",
      "Volumes Sold: 1,231,957\n",
      "Publisher: HarperCollins\n",
      "Genre: Biography: The Arts\n",
      "\n",
      "Book Name: Child Called It,A\n",
      "Author Name: Pelzer, Dave\n",
      "Volumes Sold: 1,217,712\n",
      "Publisher: Orion\n",
      "Genre: Autobiography: General\n",
      "\n",
      "Book Name: Gruffalo's Child,The\n",
      "Author Name: Donaldson, Julia\n",
      "Volumes Sold: 1,208,711\n",
      "Publisher: Pan Macmillan\n",
      "Genre: Picture Books\n",
      "\n",
      "Book Name: Angela's Ashes:A Memoir of a Childhood\n",
      "Author Name: McCourt, Frank\n",
      "Volumes Sold: 1,204,058\n",
      "Publisher: HarperCollins\n",
      "Genre: Autobiography: General\n",
      "\n",
      "Book Name: Birdsong\n",
      "Author Name: Faulks, Sebastian\n",
      "Volumes Sold: 1,184,967\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Northern Lights:His Dark Materials S.\n",
      "Author Name: Pullman, Philip\n",
      "Volumes Sold: 1,181,503\n",
      "Publisher: Scholastic Ltd.\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: Labyrinth\n",
      "Author Name: Mosse, Kate\n",
      "Volumes Sold: 1,181,093\n",
      "Publisher: Orion\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Harry Potter and the Half-blood Prince\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 1,153,181\n",
      "Publisher: Bloomsbury\n",
      "Genre: Science Fiction & Fantasy\n",
      "\n",
      "Book Name: Help,The\n",
      "Author Name: Stockett, Kathryn\n",
      "Volumes Sold: 1,132,336\n",
      "Publisher: Penguin\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Man and Boy\n",
      "Author Name: Parsons, Tony\n",
      "Volumes Sold: 1,130,802\n",
      "Publisher: HarperCollins\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Memoirs of a Geisha\n",
      "Author Name: Golden, Arthur\n",
      "Volumes Sold: 1,126,337\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\n",
      "Author Name: McCall Smith, Alexander\n",
      "Volumes Sold: 1,115,549\n",
      "Publisher: Little, Brown Book\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Island,The\n",
      "Author Name: Hislop, Victoria\n",
      "Volumes Sold: 1,108,328\n",
      "Publisher: Headline\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: PS, I Love You\n",
      "Author Name: Ahern, Cecelia\n",
      "Volumes Sold: 1,107,379\n",
      "Publisher: HarperCollins\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: You are What You Eat:The Plan That Will Change Your Life\n",
      "Author Name: McKeith, Gillian\n",
      "Volumes Sold: 1,104,403\n",
      "Publisher: Penguin\n",
      "Genre: Fitness & Diet\n",
      "\n",
      "Book Name: Shadow of the Wind,The\n",
      "Author Name: Zafon, Carlos Ruiz\n",
      "Volumes Sold: 1,092,349\n",
      "Publisher: Orion\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Tales of Beedle the Bard,The\n",
      "Author Name: Rowling, J.K.\n",
      "Volumes Sold: 1,090,847\n",
      "Publisher: Bloomsbury\n",
      "Genre: Children's Fiction\n",
      "\n",
      "Book Name: Broker,The\n",
      "Author Name: Grisham, John\n",
      "Volumes Sold: 1,087,262\n",
      "Publisher: Random House\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\n",
      "Author Name: Atkins, Robert C.\n",
      "Volumes Sold: 1,054,196\n",
      "Publisher: Random House\n",
      "Genre: Fitness & Diet\n",
      "\n",
      "Book Name: Subtle Knife,The:His Dark Materials S.\n",
      "Author Name: Pullman, Philip\n",
      "Volumes Sold: 1,037,160\n",
      "Publisher: Scholastic Ltd.\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation\n",
      "Author Name: Truss, Lynne\n",
      "Volumes Sold: 1,023,688\n",
      "Publisher: Profile Books Group\n",
      "Genre: Usage & Writing Guides\n",
      "\n",
      "Book Name: Delia's How to Cook:(Bk.1)\n",
      "Author Name: Smith, Delia\n",
      "Volumes Sold: 1,015,956\n",
      "Publisher: Random House\n",
      "Genre: Food & Drink: General\n",
      "\n",
      "Book Name: Chocolat\n",
      "Author Name: Harris, Joanne\n",
      "Volumes Sold: 1,009,873\n",
      "Publisher: Transworld\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Boy in the Striped Pyjamas,The\n",
      "Author Name: Boyne, John\n",
      "Volumes Sold: 1,004,414\n",
      "Publisher: Random House Childrens Books G\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: My Sister's Keeper\n",
      "Author Name: Picoult, Jodi\n",
      "Volumes Sold: 1,003,780\n",
      "Publisher: Hodder & Stoughton\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Amber Spyglass,The:His Dark Materials S.\n",
      "Author Name: Pullman, Philip\n",
      "Volumes Sold: 1,002,314\n",
      "Publisher: Scholastic Ltd.\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: To Kill a Mockingbird\n",
      "Author Name: Lee, Harper\n",
      "Volumes Sold: 998,213\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Men are from Mars, Women are from Venus:A Practical Guide for Improvin\n",
      "Author Name: Gray, John\n",
      "Volumes Sold: 992,846\n",
      "Publisher: HarperCollins\n",
      "Genre: Popular Culture & Media: General Interest\n",
      "\n",
      "Book Name: Dear Fatty\n",
      "Author Name: French, Dawn\n",
      "Volumes Sold: 986,753\n",
      "Publisher: Random House\n",
      "Genre: Autobiography: The Arts\n",
      "\n",
      "Book Name: Short History of Tractors in Ukrainian,A\n",
      "Author Name: Lewycka, Marina\n",
      "Volumes Sold: 986,115\n",
      "Publisher: Penguin\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Hannibal\n",
      "Author Name: Harris, Thomas\n",
      "Volumes Sold: 970,509\n",
      "Publisher: Random House\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Lord of the Rings,The\n",
      "Author Name: Tolkien, J. R. R.\n",
      "Volumes Sold: 967,466\n",
      "Publisher: HarperCollins\n",
      "Genre: Science Fiction & Fantasy\n",
      "\n",
      "Book Name: Stupid White Men:...and Other Sorry Excuses for the State of the Natio\n",
      "Author Name: Moore, Michael\n",
      "Volumes Sold: 963,353\n",
      "Publisher: Penguin\n",
      "Genre: Current Affairs & Issues\n",
      "\n",
      "Book Name: Interpretation of Murder,The\n",
      "Author Name: Rubenfeld, Jed\n",
      "Volumes Sold: 962,515\n",
      "Publisher: Headline\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Sharon Osbourne Extreme:My Autobiography\n",
      "Author Name: Osbourne, Sharon\n",
      "Volumes Sold: 959,496\n",
      "Publisher: Little, Brown Book\n",
      "Genre: Autobiography: The Arts\n",
      "\n",
      "Book Name: Alchemist,The:A Fable About Following Your Dream\n",
      "Author Name: Coelho, Paulo\n",
      "Volumes Sold: 956,114\n",
      "Publisher: HarperCollins\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: At My Mother's Knee ...:and Other Low Joints\n",
      "Author Name: O'Grady, Paul\n",
      "Volumes Sold: 945,640\n",
      "Publisher: Transworld\n",
      "Genre: Autobiography: The Arts\n",
      "\n",
      "Book Name: Notes from a Small Island\n",
      "Author Name: Bryson, Bill\n",
      "Volumes Sold: 931,312\n",
      "Publisher: Transworld\n",
      "Genre: Travel Writing\n",
      "\n",
      "Book Name: Return of the Naked Chef,The\n",
      "Author Name: Oliver, Jamie\n",
      "Volumes Sold: 925,425\n",
      "Publisher: Penguin\n",
      "Genre: Food & Drink: General\n",
      "\n",
      "Book Name: Bridget Jones: The Edge of Reason\n",
      "Author Name: Fielding, Helen\n",
      "Volumes Sold: 924,695\n",
      "Publisher: Pan Macmillan\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Jamie's Italy\n",
      "Author Name: Oliver, Jamie\n",
      "Volumes Sold: 906,968\n",
      "Publisher: Penguin\n",
      "Genre: National & Regional Cuisine\n",
      "\n",
      "Book Name: I Can Make You Thin\n",
      "Author Name: McKenna, Paul\n",
      "Volumes Sold: 905,086\n",
      "Publisher: Transworld\n",
      "Genre: Fitness & Diet\n",
      "\n",
      "Book Name: Down Under\n",
      "Author Name: Bryson, Bill\n",
      "Volumes Sold: 890,847\n",
      "Publisher: Transworld\n",
      "Genre: Travel Writing\n",
      "\n",
      "Book Name: Summons,The\n",
      "Author Name: Grisham, John\n",
      "Volumes Sold: 869,671\n",
      "Publisher: Random House\n",
      "Genre: Crime, Thriller & Adventure\n",
      "\n",
      "Book Name: Small Island\n",
      "Author Name: Levy, Andrea\n",
      "Volumes Sold: 869,659\n",
      "Publisher: Headline\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Nigella Express\n",
      "Author Name: Lawson, Nigella\n",
      "Volumes Sold: 862,602\n",
      "Publisher: Random House\n",
      "Genre: Food & Drink: General\n",
      "\n",
      "Book Name: Brick Lane\n",
      "Author Name: Ali, Monica\n",
      "Volumes Sold: 856,540\n",
      "Publisher: Transworld\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Memory Keeper's Daughter,The\n",
      "Author Name: Edwards, Kim\n",
      "Volumes Sold: 845,858\n",
      "Publisher: Penguin\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Room on the Broom\n",
      "Author Name: Donaldson, Julia\n",
      "Volumes Sold: 842,535\n",
      "Publisher: Pan Macmillan\n",
      "Genre: Picture Books\n",
      "\n",
      "Book Name: About a Boy\n",
      "Author Name: Hornby, Nick\n",
      "Volumes Sold: 828,215\n",
      "Publisher: Penguin\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: My Booky Wook\n",
      "Author Name: Brand, Russell\n",
      "Volumes Sold: 820,563\n",
      "Publisher: Hodder & Stoughton\n",
      "Genre: Autobiography: The Arts\n",
      "\n",
      "Book Name: God Delusion,The\n",
      "Author Name: Dawkins, Richard\n",
      "Volumes Sold: 816,907\n",
      "Publisher: Transworld\n",
      "Genre: Popular Science\n",
      "\n",
      "Book Name: \"Beano\" Annual,The\n",
      "Author Name: 0\n",
      "Volumes Sold: 816,585\n",
      "Publisher: D.C. Thomson\n",
      "Genre: Children's Annuals\n",
      "\n",
      "Book Name: White Teeth\n",
      "Author Name: Smith, Zadie\n",
      "Volumes Sold: 815,586\n",
      "Publisher: Penguin\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: House at Riverton,The\n",
      "Author Name: Morton, Kate\n",
      "Volumes Sold: 814,370\n",
      "Publisher: Pan Macmillan\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Book Thief,The\n",
      "Author Name: Zusak, Markus\n",
      "Volumes Sold: 809,641\n",
      "Publisher: Transworld\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Nights of Rain and Stars\n",
      "Author Name: Binchy, Maeve\n",
      "Volumes Sold: 808,900\n",
      "Publisher: Orion\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Ghost,The\n",
      "Author Name: Harris, Robert\n",
      "Volumes Sold: 807,311\n",
      "Publisher: Random House\n",
      "Genre: General & Literary Fiction\n",
      "\n",
      "Book Name: Happy Days with the Naked Chef\n",
      "Author Name: Oliver, Jamie\n",
      "Volumes Sold: 794,201\n",
      "Publisher: Penguin\n",
      "Genre: Food & Drink: General\n",
      "\n",
      "Book Name: Hunger Games,The:Hunger Games Trilogy\n",
      "Author Name: Collins, Suzanne\n",
      "Volumes Sold: 792,187\n",
      "Publisher: Scholastic Ltd.\n",
      "Genre: Young Adult Fiction\n",
      "\n",
      "Book Name: Lost Boy,The:A Foster Child's Search for the Love of a Family\n",
      "Author Name: Pelzer, Dave\n",
      "Volumes Sold: 791,507\n",
      "Publisher: Orion\n",
      "Genre: Biography: General\n",
      "\n",
      "Book Name: Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\n",
      "Author Name: Oliver, Jamie\n",
      "Volumes Sold: 791,095\n",
      "Publisher: Penguin\n",
      "Genre: Food & Drink: General\n",
      "\n",
      "                                            Book Name       Author Name  \\\n",
      "0                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "1            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "2           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "3                                Fifty Shades of Grey      James, E. L.   \n",
      "4                 Harry Potter and the Goblet of Fire     Rowling, J.K.   \n",
      "..                                                ...               ...   \n",
      "94                                          Ghost,The    Harris, Robert   \n",
      "95                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "96              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "97  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "98  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "   Volumes Sold        Publisher                       Genre  \n",
      "0     4,475,152       Bloomsbury          Children's Fiction  \n",
      "1     4,200,654       Bloomsbury          Children's Fiction  \n",
      "2     4,179,479       Bloomsbury          Children's Fiction  \n",
      "3     3,758,936     Random House             Romance & Sagas  \n",
      "4     3,583,215       Bloomsbury          Children's Fiction  \n",
      "..          ...              ...                         ...  \n",
      "94      807,311     Random House  General & Literary Fiction  \n",
      "95      794,201          Penguin       Food & Drink: General  \n",
      "96      792,187  Scholastic Ltd.         Young Adult Fiction  \n",
      "97      791,507            Orion          Biography: General  \n",
      "98      791,095          Penguin       Food & Drink: General  \n",
      "\n",
      "[99 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Wait for the table to load\n",
    "table = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//table[@class='in-article sortable']\")))\n",
    "\n",
    "# Create empty lists for each data point\n",
    "book_names = []\n",
    "author_names = []\n",
    "volumes_sold = []\n",
    "publishers = []\n",
    "genres = []\n",
    "\n",
    "# Find all rows in the table except for the header row\n",
    "rows = table.find_elements(By.XPATH, \".//tr[position()>1]\")\n",
    "\n",
    "# Iterate over each row and extract the data points\n",
    "for row in rows:\n",
    "    # Extract the data from each cell in the row\n",
    "    cells = row.find_elements(By.XPATH, \".//td\")\n",
    "    \n",
    "    # Extract the book name\n",
    "    book_name = cells[1].text.strip()\n",
    "    book_names.append(book_name)\n",
    "    print(f\"Book Name: {book_name}\")\n",
    "    \n",
    "    # Extract the author name\n",
    "    author_name = cells[2].text.strip()\n",
    "    author_names.append(author_name)\n",
    "    print(f\"Author Name: {author_name}\")\n",
    "    \n",
    "    # Extract the volumes sold\n",
    "    volumes = cells[3].text.strip()\n",
    "    volumes_sold.append(volumes)\n",
    "    print(f\"Volumes Sold: {volumes}\")\n",
    "    \n",
    "    # Extract the publisher\n",
    "    publisher = cells[4].text.strip()\n",
    "    publishers.append(publisher)\n",
    "    print(f\"Publisher: {publisher}\")\n",
    "    \n",
    "    # Extract the genre\n",
    "    genre = cells[5].text.strip()\n",
    "    genres.append(genre)\n",
    "    print(f\"Genre: {genre}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Create a Pandas DataFrame to store the data\n",
    "data = {\n",
    "    \"Book Name\": book_names,\n",
    "    \"Author Name\": author_names,\n",
    "    \"Volumes Sold\": volumes_sold,\n",
    "    \"Publisher\": publishers,\n",
    "    \"Genre\": genres}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "266e29dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8863c38",
   "metadata": {},
   "source": [
    "MOST WATCHED TV SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd296fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d95afb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching the chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7359d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f60e6920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name       year                     genre  \\\n",
      "0                  Game of Thrones  2011–2019  Action, Adventure, Drama   \n",
      "1                  Stranger Things  2016–2024    Drama, Fantasy, Horror   \n",
      "2                 The Walking Dead  2010–2022   Drama, Horror, Thriller   \n",
      "3                   13 Reasons Why  2017–2020  Drama, Mystery, Thriller   \n",
      "4                          The 100  2014–2020    Drama, Mystery, Sci-Fi   \n",
      "..                             ...        ...                       ...   \n",
      "95                           Reign  2013–2017                     Drama   \n",
      "96  A Series of Unfortunate Events  2017–2019  Adventure, Comedy, Drama   \n",
      "97                  Criminal Minds     2005–      Crime, Drama, Mystery   \n",
      "98           Scream: The TV Series  2015–2019      Comedy, Crime, Drama   \n",
      "99      The Haunting of Hill House       2018    Drama, Horror, Mystery   \n",
      "\n",
      "    runtime rating votes  \n",
      "0    57 min    9.2  None  \n",
      "1    51 min    8.7  None  \n",
      "2    44 min    8.1  None  \n",
      "3    60 min    7.5  None  \n",
      "4    43 min    7.6  None  \n",
      "..      ...    ...   ...  \n",
      "95   42 min    7.4  None  \n",
      "96   50 min    7.8  None  \n",
      "97   42 min    8.1  None  \n",
      "98   45 min    7.1  None  \n",
      "99  572 min    8.6  None  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "\n",
    "# create empty lists to store data\n",
    "names = []\n",
    "year_spans = []\n",
    "genres = []\n",
    "runtimes = []\n",
    "ratings = []\n",
    "votes = []\n",
    "\n",
    "tv_list = driver.find_elements(By.XPATH, '//div[@class=\"lister-item-content\"]')\n",
    "tv_details = []\n",
    "\n",
    "for tv in tv_list:\n",
    "    # name\n",
    "    name = tv.find_element(By.XPATH, './/h3/a').text\n",
    "    # year\n",
    "    year = tv.find_element(By.XPATH, './/span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "    year = year.text.replace('(','').replace(')','')\n",
    "    # genre\n",
    "    genre = tv.find_element(By.XPATH, './/span[@class=\"genre\"]')\n",
    "    genre = genre.text.strip()\n",
    "    # runtime\n",
    "    runtime = tv.find_element(By.XPATH, './/span[@class=\"runtime\"]')\n",
    "    runtime = runtime.text\n",
    "    # rating\n",
    "    rating = tv.find_element(By.XPATH, './/div[@class=\"ipl-rating-star small\"]/span[@class=\"ipl-rating-star__rating\"]')\n",
    "    rating = rating.text\n",
    "    # votes\n",
    "    try:\n",
    "        vote = tv.find_element(By.XPATH, './/span[@name=\"ir\"]')\n",
    "        votes = vote.get_attribute('data-value')\n",
    "    except:\n",
    "        votes = None\n",
    "        \n",
    "    tv_details.append({\n",
    "        'name': name,\n",
    "        'year': year,\n",
    "        'genre': genre,\n",
    "        'runtime': runtime,\n",
    "        'rating': rating,\n",
    "        'votes': votes})\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(tv_details)\n",
    "print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e6e016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427cc56",
   "metadata": {},
   "source": [
    "DATASETS FROM UCI MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279ae324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d57267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching the chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b97c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the url\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fa3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the ShowAllDataset page\n",
    "show_all_dataset = driver.find_element(By.XPATH, \"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "show_all_dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b504a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the dataset details\n",
    "dataset_names = []\n",
    "data_types = []\n",
    "tasks = []\n",
    "attribute_types = []\n",
    "no_of_instances = []\n",
    "no_of_attributes = []\n",
    "years = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc48624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Dataset Name, Data Type, Task, Attribute Type, No of Instances, No of Attributes, Year]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# get the list of all datasets on the page\n",
    "datasets = driver.find_elements(By.XPATH, \"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]\")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# loop through the rows of the table and get the details of each dataset\n",
    "dataset_details = []\n",
    "for row in datasets[1:]:\n",
    "    details = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    dataset_name = details[0].text\n",
    "    data_type = details[1].text\n",
    "    if len(details) > 2:\n",
    "        task = details[2].text\n",
    "    else:\n",
    "        task = \"\"\n",
    "    if len(details) > 3:\n",
    "        attribute_type = details[3].text\n",
    "    else:\n",
    "        attribute_type = \"\"\n",
    "    if len(details) > 4:\n",
    "        no_of_instances = details[4].text\n",
    "    else:\n",
    "        no_of_instances = \"\"\n",
    "    if len(details) > 5:\n",
    "        no_of_attributes = details[5].text\n",
    "    else:\n",
    "        no_of_attributes = \"\"\n",
    "    year = details[-1].text\n",
    "    dataset_details.append([dataset_name, data_type, task, attribute_type, no_of_instances, no_of_attributes, year])\n",
    "\n",
    "\n",
    "# create a dataframe from the dataset details list\n",
    "df = pd.DataFrame(dataset_details, columns=['Dataset Name', 'Data Type', 'Task', 'Attribute Type', 'No of Instances', 'No of Attributes', 'Year'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b01ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe1c5b",
   "metadata": {},
   "source": [
    "DATA SCIENCE RECRUITERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f637226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a921d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sukanyasemwal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b975f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching the chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea0787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate the url\n",
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5df9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter \"Data Science\" in the search field and click on the search button\n",
    "# Wait for up to 10 seconds for the element to be interactable\n",
    "wait = WebDriverWait(driver, 10)\n",
    "search_field = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')))\n",
    "search_field.send_keys(\"Data Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c72366",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5f1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty table to save data\n",
    "recruiters_data = []\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "# Loop through the first 50 recruiter listings and extract their details\n",
    "for i in range(1, 51):\n",
    "    # Find the elements containing the recruiter's details\n",
    "    name_element = driver.find_elements(By.XPATH, f'/html/body/div[3]/div/div[2]/div/div[2]/div[{i}]/div[1]/div[1]/div[1]/p/a[1]')\n",
    "    designation_element = driver.find_elements(By.XPATH, f'/html/body/div[3]/div/div[2]/div/div[2]/div[{i}]/div[1]/div[1]/div[1]/p/span[1]')\n",
    "    company_element = driver.find_elements(By.XPATH, f'/html/body/div[3]/div/div[2]/div/div[2]/div[{i}]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "    skills_element = driver.find_elements(By.XPATH, f'/html/body/div[3]/div/div[2]/div/div[2]/div[{i}]/div[1]/div[1]/div[2]')\n",
    "    location_element = driver.find_elements(By.XPATH, f'/html/body/div[3]/div/div[2]/div/div[2]/div[{i}]/div[1]/div[1]/div[1]/p/span[2]/small')\n",
    "    \n",
    "    # Extract the text from the elements\n",
    "    name_text = name_element[0].text if name_element else ''\n",
    "    designation_text = designation_element[0].text if designation_element else ''\n",
    "    company_text = company_element[0].text if company_element else ''\n",
    "    skills_text = skills_element[0].text if skills_element else ''\n",
    "    location_text = location_element[0].text if location_element else ''\n",
    "\n",
    "    # Add the recruiter's details to the table\n",
    "    recruiters_data.append([name_text, designation_text, company_text, skills_text, location_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf9a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Aakash Harit\n",
      "Designation: HR Manager\n",
      "Company: Data Science Network\n",
      "Skills: Classic ASP Developer, Internet Marketing Professional, Data Science SME, Content Writers, SEO Professional, Revenue Professional\n",
      "Location: Delhi\n",
      "-----\n",
      "Name: MARSIAN Technologies LLP\n",
      "Designation: Company HR\n",
      "Company: MARSIAN Technologies LLP\n",
      "Skills: Data Science, Artificial Intelligence, Machine Learning, Business Analytics, Deep Learning, statistics, Data Analytics, Data Analysis, support vector machine\n",
      "Location: Pune\n",
      "-----\n",
      "Name: subhas patel\n",
      "Designation: Founder CEO\n",
      "Company: LibraryXProject\n",
      "Skills: Hadoop, Spark, Digital Strategy, Data Architecture, Command Center, Cdp, Dmp, Kafka, Data Science, Data Analysis, Big Data Analytics, Real Time Analysis, SQL\n",
      "Location: UK - (london)\n",
      "-----\n",
      "Name: Institute for Financial Management and Resear\n",
      "Designation: Programme Manager\n",
      "Company: IFMR\n",
      "Skills: Data Science\n",
      "Location: Chennai\n",
      "-----\n",
      "Name: Asif Lucknowi\n",
      "Designation: Director\n",
      "Company: Weupskill- Live Wire India\n",
      "Skills: Technical Training, Software Development, Presentation Skills, B.tech, M.tech, B.e., mca, msc, Computer Science, freshers, jobs in indore, Data Science, itil\n",
      "Location: Indore\n",
      "-----\n",
      "Name: Kalpana Dumpala\n",
      "Designation: Executive Hiring\n",
      "Company: Innominds Software\n",
      "Skills: Qa, Ui/ux, Java Developer, Java Architect, C++/qt, Php, Lamp, Api, J2ee, Java, Soa, Esb, Middleware, Bigdata Achitect, Hadoop Architect, Deep\n",
      "Location: Hyderabad / Secunderabad\n",
      "-----\n",
      "Name: Kushal Rastogi\n",
      "Designation: Company HR\n",
      "Company: QuantMagnum Technologies Pvt. Ltd.\n",
      "Skills: Office Administration, Hr Administration, telecalling, client relationship management, Client Acquisition, Sales, Reception, HR, Recruitment, Onboarding, Human\n",
      "Location: Mumbai\n",
      "-----\n",
      "Name: Priyanka Akiri\n",
      "Designation: HR Manager\n",
      "Company: Infinitive Software Solutions\n",
      "Skills: Oracle Dba, Data Science, Data Warehousing, ETL, Jupyter, Numpy, Data Transformation, Snowflake, Teradata, Python, Data Manipulation, Relational Databases\n",
      "Location: Hyderabad\n",
      "-----\n",
      "Name: Vaishnavi Kudalkar\n",
      "Designation: HR Executive\n",
      "Company: Codeachive learning\n",
      "Skills: Data Science, Python, Data Analytics\n",
      "Location: Mumbai\n",
      "-----\n",
      "Name: Ruchi Dhote\n",
      "Designation: Senior Executive Talent Acquisition\n",
      "Company: Bristlecone India Ltd\n",
      "Skills: Qlikview, Qlik Sense, Microsoft Azure, Power Bi, Data Science, Machine Learning\n",
      "Location: Pune\n",
      "-----\n",
      "Name: Riya Rajesh\n",
      "Designation: Manager Talent Acquisition\n",
      "Company: Novelworx Digital Solutions\n",
      "Skills: Data Science\n",
      "Location: Cochin\n",
      "-----\n",
      "Name: Faizan Kareem\n",
      "Designation: HR MANAGER\n",
      "Company: FirstTech Consaltants Pvt.Ltd\n",
      "Skills: Data Analytics, Data Science, Machine Learning, Deep Learning, Nlp, Data Mining, Python, R, Database Administration, Text Mining\n",
      "Location: Hyderabad / Secunderabad\n",
      "-----\n",
      "Name: Sandhya Khandagale\n",
      "Designation: HR Recruiter\n",
      "Company: Compumatrice Multimedia Pvt Ltd\n",
      "Skills: Big Data, Data Science, Artificial Intelligence, Hadoop, Ui Development, Php, Freelancing, .Net, Software Testing, Sap, Leadership Hiring\n",
      "Location: Pune\n",
      "-----\n",
      "Name: Deeparchi Sharma\n",
      "Designation: Company Recruiter\n",
      "Company: ZIGRAM\n",
      "Skills: Research, Digital Marketing, Analytics, Software Development, Data Science, Consulting\n",
      "Location: Gurgaon\n",
      "-----\n",
      "Name: Manas\n",
      "Designation: Lead Talent acquisition\n",
      "Company: Autumn Leaf Consulting Services Private...\n",
      "Skills: Software Architecture, Vp Engineering, Product Management, analytics, Data Science, Node.js, Principal Engineer, Big Data, python, angularjs, React.js\n",
      "Location: Bengaluru / Bangalore\n",
      "-----\n",
      "Name: Sunil Vedula\n",
      "Designation: CEO\n",
      "Company: Nanoprecise Sci Corp\n",
      "Skills: Signal Processing, Machine Learning, Neural Networks, Data Science, Predictive Analytics, Time Series Analysis, Data Visualization, Technical Leadership, Data\n",
      "Location: \n",
      "-----\n",
      "Name: Dhruv Dev Dubey\n",
      "Designation: Company Recruitment Head\n",
      "Company: NETAPS FOUNDATION\n",
      "Skills: Server Administartion, Verilog, Vhdl, Digital Marketing, Market Research, Property Research, Legal, It And Non It Recruitment, Logistics, Supply Chain, Bfsi\n",
      "Location: Bengaluru / Bangalore\n",
      "-----\n",
      "Name: Jayanth N\n",
      "Designation: Project Manager\n",
      "Company: Dollarbird Information Services Pvt, Ltd\n",
      "Skills: Data Analytics, Managed Services, Team Leading, python, Machine Learning, Google Analytics, Dmp, Aws, Campaign Analytics, Digital Campaigns, Audience\n",
      "Location: Mysoru / Mysore\n",
      "-----\n",
      "Name: Priya Khare\n",
      "Designation: Senior Manager\n",
      "Company: Independent Consultant\n",
      "Skills: Data Science, Artificial Intelligence, analytics, Business Intelligence, python, tableau, Power Bi, qlikview, sql, Data Warehousing, Data Visualization\n",
      "Location: Bengaluru / Bangalore\n",
      "-----\n",
      "Name: Kanan\n",
      "Designation: senior technology instructor\n",
      "Company: NY INST\n",
      "Skills: C, C++, Artificial Intelligence, Python, Php, Web Development, Matlab, Data Science, Augmented Reality, C C++\n",
      "Location: Chennai\n",
      "-----\n",
      "Name: Brad\n",
      "Designation: Manager, Technical Recruiting\n",
      "Company: O.C. Tanner\n",
      "Skills: Data Science, Software Engineering\n",
      "Location: Salt Lake City\n",
      "-----\n",
      "Name: Madhusudhan Sridhar\n",
      "Designation: Erp Implementer\n",
      "Company: MADHUSUDHAN SRIDHAR\n",
      "Skills: Data Science, Recruitment, Salary\n",
      "Location: Bengaluru / Bangalore\n",
      "-----\n",
      "Name: Gaurav Chouhan\n",
      "Designation: Chief Technical Officer\n",
      "Company: Strategic Consulting Lab\n",
      "Skills: Software Development, Business Intelligence, Big Data Analytics, Database Administration, Data Science, Microsoft Azure, Spark, Cassandra, Object Oriented\n",
      "Location: Indore\n",
      "-----\n",
      "Name: Ashwini\n",
      "Designation: Director Global Delivery\n",
      "Company: MRP Advisers\n",
      "Skills: Data Science, Media Marketing, Resource Planning, Managed Services, Display Advertising, Machine Learning, Python, Etl, Sql\n",
      "Location: MYSORE\n",
      "-----\n",
      "Name: Rajani Nagaraj\n",
      "Designation: HR Manager\n",
      "Company: WildJasmine\n",
      "Skills: Java, Hadoop, R, Machine Learning, Spark, Flume, Hdfs, Data Mining, Sas, Big, Data Science, Cloudera, Impala, Bigdata\n",
      "Location: Bengaluru / Bangalore\n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n",
      "Name: \n",
      "Designation: \n",
      "Company: \n",
      "Skills: \n",
      "Location: \n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "time.sleep(10)\n",
    "# Print the recruiter details\n",
    "for recruiter in recruiters_data:\n",
    "    print(f\"Name: {recruiter[0]}\")\n",
    "    print(f\"Designation: {recruiter[1]}\")\n",
    "    print(f\"Company: {recruiter[2]}\")\n",
    "    print(f\"Skills: {recruiter[3]}\")\n",
    "    print(f\"Location: {recruiter[4]}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1965a9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Name  \\\n",
      "0                                    Aakash Harit   \n",
      "1                        MARSIAN Technologies LLP   \n",
      "2                                    subhas patel   \n",
      "3   Institute for Financial Management and Resear   \n",
      "4                                   Asif Lucknowi   \n",
      "5                                 Kalpana Dumpala   \n",
      "6                                  Kushal Rastogi   \n",
      "7                                  Priyanka Akiri   \n",
      "8                              Vaishnavi Kudalkar   \n",
      "9                                     Ruchi Dhote   \n",
      "10                                    Riya Rajesh   \n",
      "11                                  Faizan Kareem   \n",
      "12                             Sandhya Khandagale   \n",
      "13                               Deeparchi Sharma   \n",
      "14                                          Manas   \n",
      "15                                   Sunil Vedula   \n",
      "16                                Dhruv Dev Dubey   \n",
      "17                                      Jayanth N   \n",
      "18                                    Priya Khare   \n",
      "19                                          Kanan   \n",
      "20                                           Brad   \n",
      "21                            Madhusudhan Sridhar   \n",
      "22                                 Gaurav Chouhan   \n",
      "23                                        Ashwini   \n",
      "24                                 Rajani Nagaraj   \n",
      "25                                                  \n",
      "26                                                  \n",
      "27                                                  \n",
      "28                                                  \n",
      "29                                                  \n",
      "30                                                  \n",
      "31                                                  \n",
      "32                                                  \n",
      "33                                                  \n",
      "34                                                  \n",
      "35                                                  \n",
      "36                                                  \n",
      "37                                                  \n",
      "38                                                  \n",
      "39                                                  \n",
      "40                                                  \n",
      "41                                                  \n",
      "42                                                  \n",
      "43                                                  \n",
      "44                                                  \n",
      "45                                                  \n",
      "46                                                  \n",
      "47                                                  \n",
      "48                                                  \n",
      "49                                                  \n",
      "\n",
      "                            Designation  \\\n",
      "0                            HR Manager   \n",
      "1                            Company HR   \n",
      "2                           Founder CEO   \n",
      "3                     Programme Manager   \n",
      "4                              Director   \n",
      "5                      Executive Hiring   \n",
      "6                            Company HR   \n",
      "7                            HR Manager   \n",
      "8                          HR Executive   \n",
      "9   Senior Executive Talent Acquisition   \n",
      "10           Manager Talent Acquisition   \n",
      "11                           HR MANAGER   \n",
      "12                         HR Recruiter   \n",
      "13                    Company Recruiter   \n",
      "14              Lead Talent acquisition   \n",
      "15                                  CEO   \n",
      "16             Company Recruitment Head   \n",
      "17                      Project Manager   \n",
      "18                       Senior Manager   \n",
      "19         senior technology instructor   \n",
      "20        Manager, Technical Recruiting   \n",
      "21                      Erp Implementer   \n",
      "22              Chief Technical Officer   \n",
      "23             Director Global Delivery   \n",
      "24                           HR Manager   \n",
      "25                                        \n",
      "26                                        \n",
      "27                                        \n",
      "28                                        \n",
      "29                                        \n",
      "30                                        \n",
      "31                                        \n",
      "32                                        \n",
      "33                                        \n",
      "34                                        \n",
      "35                                        \n",
      "36                                        \n",
      "37                                        \n",
      "38                                        \n",
      "39                                        \n",
      "40                                        \n",
      "41                                        \n",
      "42                                        \n",
      "43                                        \n",
      "44                                        \n",
      "45                                        \n",
      "46                                        \n",
      "47                                        \n",
      "48                                        \n",
      "49                                        \n",
      "\n",
      "                                       Company  \\\n",
      "0                         Data Science Network   \n",
      "1                     MARSIAN Technologies LLP   \n",
      "2                              LibraryXProject   \n",
      "3                                         IFMR   \n",
      "4                   Weupskill- Live Wire India   \n",
      "5                           Innominds Software   \n",
      "6           QuantMagnum Technologies Pvt. Ltd.   \n",
      "7                Infinitive Software Solutions   \n",
      "8                          Codeachive learning   \n",
      "9                        Bristlecone India Ltd   \n",
      "10                 Novelworx Digital Solutions   \n",
      "11               FirstTech Consaltants Pvt.Ltd   \n",
      "12             Compumatrice Multimedia Pvt Ltd   \n",
      "13                                      ZIGRAM   \n",
      "14  Autumn Leaf Consulting Services Private...   \n",
      "15                        Nanoprecise Sci Corp   \n",
      "16                           NETAPS FOUNDATION   \n",
      "17    Dollarbird Information Services Pvt, Ltd   \n",
      "18                      Independent Consultant   \n",
      "19                                     NY INST   \n",
      "20                                 O.C. Tanner   \n",
      "21                         MADHUSUDHAN SRIDHAR   \n",
      "22                    Strategic Consulting Lab   \n",
      "23                                MRP Advisers   \n",
      "24                                 WildJasmine   \n",
      "25                                               \n",
      "26                                               \n",
      "27                                               \n",
      "28                                               \n",
      "29                                               \n",
      "30                                               \n",
      "31                                               \n",
      "32                                               \n",
      "33                                               \n",
      "34                                               \n",
      "35                                               \n",
      "36                                               \n",
      "37                                               \n",
      "38                                               \n",
      "39                                               \n",
      "40                                               \n",
      "41                                               \n",
      "42                                               \n",
      "43                                               \n",
      "44                                               \n",
      "45                                               \n",
      "46                                               \n",
      "47                                               \n",
      "48                                               \n",
      "49                                               \n",
      "\n",
      "                                 Skills they hire for  \\\n",
      "0   Classic ASP Developer, Internet Marketing Prof...   \n",
      "1   Data Science, Artificial Intelligence, Machine...   \n",
      "2   Hadoop, Spark, Digital Strategy, Data Architec...   \n",
      "3                                        Data Science   \n",
      "4   Technical Training, Software Development, Pres...   \n",
      "5   Qa, Ui/ux, Java Developer, Java Architect, C++...   \n",
      "6   Office Administration, Hr Administration, tele...   \n",
      "7   Oracle Dba, Data Science, Data Warehousing, ET...   \n",
      "8                Data Science, Python, Data Analytics   \n",
      "9   Qlikview, Qlik Sense, Microsoft Azure, Power B...   \n",
      "10                                       Data Science   \n",
      "11  Data Analytics, Data Science, Machine Learning...   \n",
      "12  Big Data, Data Science, Artificial Intelligenc...   \n",
      "13  Research, Digital Marketing, Analytics, Softwa...   \n",
      "14  Software Architecture, Vp Engineering, Product...   \n",
      "15  Signal Processing, Machine Learning, Neural Ne...   \n",
      "16  Server Administartion, Verilog, Vhdl, Digital ...   \n",
      "17  Data Analytics, Managed Services, Team Leading...   \n",
      "18  Data Science, Artificial Intelligence, analyti...   \n",
      "19  C, C++, Artificial Intelligence, Python, Php, ...   \n",
      "20                 Data Science, Software Engineering   \n",
      "21                  Data Science, Recruitment, Salary   \n",
      "22  Software Development, Business Intelligence, B...   \n",
      "23  Data Science, Media Marketing, Resource Planni...   \n",
      "24  Java, Hadoop, R, Machine Learning, Spark, Flum...   \n",
      "25                                                      \n",
      "26                                                      \n",
      "27                                                      \n",
      "28                                                      \n",
      "29                                                      \n",
      "30                                                      \n",
      "31                                                      \n",
      "32                                                      \n",
      "33                                                      \n",
      "34                                                      \n",
      "35                                                      \n",
      "36                                                      \n",
      "37                                                      \n",
      "38                                                      \n",
      "39                                                      \n",
      "40                                                      \n",
      "41                                                      \n",
      "42                                                      \n",
      "43                                                      \n",
      "44                                                      \n",
      "45                                                      \n",
      "46                                                      \n",
      "47                                                      \n",
      "48                                                      \n",
      "49                                                      \n",
      "\n",
      "                    Location  \n",
      "0                      Delhi  \n",
      "1                       Pune  \n",
      "2              UK - (london)  \n",
      "3                    Chennai  \n",
      "4                     Indore  \n",
      "5   Hyderabad / Secunderabad  \n",
      "6                     Mumbai  \n",
      "7                  Hyderabad  \n",
      "8                     Mumbai  \n",
      "9                       Pune  \n",
      "10                    Cochin  \n",
      "11  Hyderabad / Secunderabad  \n",
      "12                      Pune  \n",
      "13                   Gurgaon  \n",
      "14     Bengaluru / Bangalore  \n",
      "15                            \n",
      "16     Bengaluru / Bangalore  \n",
      "17           Mysoru / Mysore  \n",
      "18     Bengaluru / Bangalore  \n",
      "19                   Chennai  \n",
      "20            Salt Lake City  \n",
      "21     Bengaluru / Bangalore  \n",
      "22                    Indore  \n",
      "23                    MYSORE  \n",
      "24     Bengaluru / Bangalore  \n",
      "25                            \n",
      "26                            \n",
      "27                            \n",
      "28                            \n",
      "29                            \n",
      "30                            \n",
      "31                            \n",
      "32                            \n",
      "33                            \n",
      "34                            \n",
      "35                            \n",
      "36                            \n",
      "37                            \n",
      "38                            \n",
      "39                            \n",
      "40                            \n",
      "41                            \n",
      "42                            \n",
      "43                            \n",
      "44                            \n",
      "45                            \n",
      "46                            \n",
      "47                            \n",
      "48                            \n",
      "49                            \n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the table\n",
    "df = pd.DataFrame(recruiters_data, columns=[\"Name\", \"Designation\", \"Company\", \"Skills they hire for\", \"Location\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da1af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57642404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
